{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Задание 1"
   ],
   "metadata": {
    "id": "IkpcHsV8RWHA"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Написать теггер на данных с руским языком**\n",
    "\n",
    "1. проверить UnigramTagger, BigramTagger, TrigramTagger и их комбмнации.\n",
    "\n",
    "2. \n",
    "   - написать свой теггер как на занятии, \n",
    "   - попробовать разные векторайзеры,\n",
    "   - добавить знание не только букв но и слов\n",
    "   \n",
    "3. сравнить все реализованные методы сделать выводы"
   ],
   "metadata": {
    "id": "aAQBOJRARev7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## загрузка данных"
   ],
   "metadata": {
    "id": "_16J0ER8WOJx"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pyconll"
   ],
   "outputs": [],
   "metadata": {
    "id": "9wgL-33mWUyZ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# from nltk.corpus import brown # Здесь, возможно необходимо будет взять только русские другую библиотеку.\n",
    "\n",
    "from nltk.tag import DefaultTagger\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.tag import BigramTagger, TrigramTagger\n",
    "from nltk.tag import RegexpTagger\n",
    "\n",
    "# tags = [tag for (word, tag) in brown.tagged_words(categories='news')]\n",
    "# nltk.FreqDist(tags)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "nltk.help.upenn_tagset('RB')\n",
    "nltk.help.upenn_tagset('NN')\n",
    "nltk.help.upenn_tagset('VB')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# !wget -O ./datasets/ru_syntagrus-ud-train.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train.conllu\n",
    "# !wget -O ./datasets/ru_syntagrus-ud-dev.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tpwgA3svWiRw",
    "outputId": "9d4e2aa6-bcc7-4793-f85d-2ce708f88ff8"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "full_train = pyconll.load_from_file('datasets/ru_syntagrus-ud-train.conllu')\n",
    "full_test = pyconll.load_from_file('datasets/ru_syntagrus-ud-dev.conllu')"
   ],
   "outputs": [],
   "metadata": {
    "id": "Oymo30RBWjjl"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Здесь можно сократить написание."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "train_data = []\n",
    "for sent in full_train[:]:\n",
    "    train_data.append([(token.form, token.upos) for token in sent])\n",
    "  \n",
    "test_data = []\n",
    "for sent in full_test[:]:\n",
    "    test_data.append([(token.form, token.upos) for token in sent])\n",
    "\n",
    "test_sents=[]      \n",
    "for sent in full_test[:]:\n",
    "    test_sents.append([token.form for token in sent])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "сгруппируем все теггеры и загоим их в одну функцию\n",
    "или сделаем все методом перебора. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. проверить UnigramTagger, BigramTagger, TrigramTagger и их комбмнации"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "default_tagger.evaluate(test_data)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {
    "id": "dj4tV8ytXTry"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "unigram_tagger = UnigramTagger(train_data)\n",
    "unigram_tagger.evaluate(test_data)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8772537323492737"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "bigram_tagger = BigramTagger(train_data, backoff=unigram_tagger)\n",
    "bigram_tagger.evaluate(test_data)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8829828463586425"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "trigram_tagger = TrigramTagger(train_data, backoff=bigram_tagger)\n",
    "trigram_tagger.evaluate(test_data)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.882081353418933"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def backoff_tagger(train_sents, tagger_classes, backoff=None):\n",
    "    for cls in tagger_classes:\n",
    "        backoff = cls(train_sents, backoff=backoff)\n",
    "    return backoff\n",
    "\n",
    "\n",
    "backoff = DefaultTagger('NN') \n",
    "tag = backoff_tagger(train_data,  \n",
    "                     [UnigramTagger, BigramTagger, TrigramTagger],  \n",
    "                     backoff = backoff) \n",
    "  \n",
    "tag.evaluate(test_data) "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8814747413473528"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. написать свой теггер как на занятии, попробовать разные векторайзеры, добавить знание не только букв но и слов"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Попробуем еще разные варианты **векторайзеров**.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Построим модель работающую на символьных н-граммах."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "train_tok = []\n",
    "train_label = []\n",
    "for sent in train_data[:]:\n",
    "    for tok in sent: # Вот здесь мы пройдемся по предложению с помощью окна.\n",
    "        train_tok.append(tok[0])\n",
    "        train_label.append('NO_TAG' if tok[1] is None else tok[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "test_tok = []\n",
    "test_label = []\n",
    "for sent in test_data[:]:\n",
    "    for tok in sent:\n",
    "        test_tok.append(tok[0])\n",
    "        test_label.append('NO_TAG' if tok[1] is None else tok[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "def get_tok_and_label(data):\n",
    "    tokens = []\n",
    "    labels = []\n",
    "    for sent in data[:]:\n",
    "        for tok in sent:\n",
    "            tokens.append(tok[0])\n",
    "            labels.append('NO_TAG' if tok[1] is None else tok[1])\n",
    "    return tokens, labels"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "train_enc_labels = le.fit_transform(train_label)\n",
    "test_enc_labels = le.transform(test_label)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "def cacl_accuracy(Vecorizer, Regression, ngram =(1,5), analyzer='char'):\n",
    "    # count-base подход. подкручив 4,3 тыс.\n",
    "\n",
    "    # if Vecorizer == HashingVectorizer:\n",
    "    #     vectorizer = Vecorizer(ngram_range=ngram, analyzer=analyzer, n_features=100)\n",
    "    # else:\n",
    "    vectorizer = Vecorizer(ngram_range=ngram, analyzer=analyzer)\n",
    "\n",
    "    X_train = vectorizer.fit_transform(train_tok)\n",
    "    X_test = vectorizer.transform(test_tok)\n",
    "\n",
    "    r = Regression #(random_state=0)\n",
    "    r.fit(X_train, train_enc_labels)\n",
    "    \n",
    "    pred = r.predict(X_test)\n",
    "      \n",
    "    accuracy = accuracy_score(test_enc_labels, pred)\n",
    "\n",
    "    return accuracy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "cacl_accuracy(HashingVectorizer, LogisticRegression(random_state=0), ngram=(1, 5))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9397600512250194"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "cacl_accuracy(HashingVectorizer, LogisticRegression(random_state=0), ngram=(2, 5))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8605129242071917"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "cacl_accuracy(CountVectorizer, LogisticRegression(random_state=0), ngram=(1, 5))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9532908704883227"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "cacl_accuracy(TfidfVectorizer, LogisticRegression(random_state=0), ngram=(1, 5))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9459356991204125"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "cacl_accuracy(CountVectorizer, LogisticRegression(random_state=0), ngram=(1, 2), analyzer='word')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7511373976342129"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "cacl_accuracy(TfidfVectorizer, LogisticRegression(random_state=0), ngram=(1, 2), analyzer='word')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7510699962929263"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "cacl_accuracy(CountVectorizer, xgb.XGBClassifier(verbosity=0), ngram=(1, 5))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9220840494725845"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "cacl_accuracy(TfidfVectorizer, xgb.XGBClassifier(verbosity=0), ngram=(1, 5))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9278468641525967"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Результат. \n",
    " Проверили разные векторайзеры, для разного к-ва символов. По итогу оказалось, что символьные N-граммы показали результат лучше чем N-граммы на словах."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Задание 2"
   ],
   "metadata": {
    "id": "cINqgGpKXURp"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "много дополнительных датасетов на русском языке\n",
    "\n",
    "https://natasha.github.io/corus/  \n",
    "https://github.com/natasha/corus"
   ],
   "metadata": {
    "id": "VCM0drjKXYet"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "мы будем использовать данные http://www.labinform.ru/pub/named_entities/"
   ],
   "metadata": {
    "id": "sUOg4C8sZNpw"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Проверить насколько хорошо работает NER**\n",
    "\n",
    "1. взять нер из nltk\n",
    "2. проверить deeppavlov\n",
    "3. написать свой нер попробовать разные подходы:\n",
    "  * передаём в сетку токен и его соседей\n",
    "  * передаём в сетку только токен\n",
    "\n",
    "4. сделать выводы по вашим экспериментам какой из подходов успешнее справляется"
   ],
   "metadata": {
    "id": "qzi6ApNLZg6X"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "при обучении своего нера незабудьте разделить выборку"
   ],
   "metadata": {
    "id": "aP1LgaNUtaOz"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# !pip install nltk\n",
    "# !pip install corus\n",
    "# !pip install razdel\n",
    "#!pip install -U spacy\n",
    "#!python -m spacy info"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib\n",
    "import pyconll\n",
    "import corus\n",
    "from corus import load_ne5\n",
    "import re\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import ru_core_news_md\n",
    "\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from nltk.tag import DefaultTagger\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.tag import BigramTagger, TrigramTagger\n",
    "from nltk.tag import RegexpTagger"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "nltk.help.upenn_tagset('RB')\n",
    "nltk.help.upenn_tagset('NN')\n",
    "nltk.help.upenn_tagset('VB')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# !wget http://www.labinform.ru/pub/named_entities/collection5.zip\n",
    "\n",
    "# !unzip collection5.zip\n",
    "\n",
    "# !rm collection5.zip\n",
    "\n",
    "# !ls"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vPVv6lhT3ftA",
    "outputId": "ae2f6c07-afc5-4093-b843-eed25d6d749b"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "dir = 'Collection5/'\n",
    "records = load_ne5(dir)\n",
    "# next(records) # Необходимо каким-то образоб обработать все тексты."
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UEdS2pAS3fod",
    "outputId": "402714b1-6931-41ce-ef39-f68080d9a29e"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "процедуры обработки взять из вебинарного ноутбука"
   ],
   "metadata": {
    "id": "GrhLNgNwQP2P"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "document = next(records)\n",
    "text = document.text\n",
    "# text\n",
    "text = re.sub('\\r\\n\\r\\n',' ',text)\n",
    "text = re.sub('\\r\\n',' ',text)\n",
    "text"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Обама назначил своего нового советника по экономическим вопросам Барак Обама в пятницу, 7 января, официально объявил о назначении нового директора Национального экономического совета администрации президента. Как передает Associated Press, им стал советник министра финансов США Джин Сперлинг (Gene Sperling). По новой должности чиновник станет главным советником Обамы по экономическим вопросам и ключевой фигурой в формировании экономической политики американского президента, влияя, в частности, на формирование федерального бюджета. Сперлинг уже возглавлял Национальный экономический совет в в 1996-2000 годах, при администрации Билла Клинтона. AP отмечает, что назначение Сперлинга стало частью перестановок в команде Обамы, последовавших за прошедшими осенью 2010 года промежуточными выборами в Конгресс, в ходе которых Республиканской партии удалось существенно укрепить свои позиции. Сообщается также, что, по мнению чиновников из президентской администрации, Сперлинг произвел на Обаму большое впечатление, когда помог ему достичь компромисса с республиканцами по вопросу о сохранении налоговых льгот. Джин Сперлинг сменит на посту главного экономического советника Ларри Саммерса (Larry Summers), который объявил о своем скором уходе еще в сентябре 2010 года. Днем ранее, 6 января, Барак Обама назначил нового главу своей администрации; им стал Уильям Дэйли (William Daley). Кроме того, в ближайшее время можно ожидать назначения нового пресс-секретаря президента, поскольку Роберт Гиббс, занимающий эту должность в настоящее время, заявил о своей скорой отставке. '"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "document.text = text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "nltk.pos_tag(nltk.word_tokenize(text)) # Как предварительно очистить все статьи в словаре."
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Обама', 'JJ'),\n",
       " ('назначил', 'NNP'),\n",
       " ('своего', 'NNP'),\n",
       " ('нового', 'NNP'),\n",
       " ('советника', 'NNP'),\n",
       " ('по', 'NNP'),\n",
       " ('экономическим', 'NNP'),\n",
       " ('вопросам', 'NNP'),\n",
       " ('Барак', 'NNP'),\n",
       " ('Обама', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('пятницу', 'NNP'),\n",
       " (',', ','),\n",
       " ('7', 'CD'),\n",
       " ('января', 'NN'),\n",
       " (',', ','),\n",
       " ('официально', 'NNP'),\n",
       " ('объявил', 'NNP'),\n",
       " ('о', 'NNP'),\n",
       " ('назначении', 'NNP'),\n",
       " ('нового', 'NNP'),\n",
       " ('директора', 'NNP'),\n",
       " ('Национального', 'NNP'),\n",
       " ('экономического', 'NNP'),\n",
       " ('совета', 'NNP'),\n",
       " ('администрации', 'NNP'),\n",
       " ('президента', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Как', 'NN'),\n",
       " ('передает', 'NN'),\n",
       " ('Associated', 'NNP'),\n",
       " ('Press', 'NNP'),\n",
       " (',', ','),\n",
       " ('им', 'NNP'),\n",
       " ('стал', 'NNP'),\n",
       " ('советник', 'NNP'),\n",
       " ('министра', 'NNP'),\n",
       " ('финансов', 'NNP'),\n",
       " ('США', 'NNP'),\n",
       " ('Джин', 'NNP'),\n",
       " ('Сперлинг', 'NNP'),\n",
       " ('(', '('),\n",
       " ('Gene', 'NNP'),\n",
       " ('Sperling', 'NNP'),\n",
       " (')', ')'),\n",
       " ('.', '.'),\n",
       " ('По', 'JJ'),\n",
       " ('новой', 'JJ'),\n",
       " ('должности', 'NN'),\n",
       " ('чиновник', 'NNP'),\n",
       " ('станет', 'NNP'),\n",
       " ('главным', 'NNP'),\n",
       " ('советником', 'NNP'),\n",
       " ('Обамы', 'NNP'),\n",
       " ('по', 'NNP'),\n",
       " ('экономическим', 'NNP'),\n",
       " ('вопросам', 'NNP'),\n",
       " ('и', 'NNP'),\n",
       " ('ключевой', 'NNP'),\n",
       " ('фигурой', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('формировании', 'NNP'),\n",
       " ('экономической', 'NNP'),\n",
       " ('политики', 'NNP'),\n",
       " ('американского', 'NNP'),\n",
       " ('президента', 'NNP'),\n",
       " (',', ','),\n",
       " ('влияя', 'NNP'),\n",
       " (',', ','),\n",
       " ('в', 'NNP'),\n",
       " ('частности', 'NNP'),\n",
       " (',', ','),\n",
       " ('на', 'NNP'),\n",
       " ('формирование', 'NNP'),\n",
       " ('федерального', 'NNP'),\n",
       " ('бюджета', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Сперлинг', 'VB'),\n",
       " ('уже', 'JJ'),\n",
       " ('возглавлял', 'NNP'),\n",
       " ('Национальный', 'NNP'),\n",
       " ('экономический', 'NNP'),\n",
       " ('совет', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('1996-2000', 'CD'),\n",
       " ('годах', 'NNP'),\n",
       " (',', ','),\n",
       " ('при', 'NNP'),\n",
       " ('администрации', 'NNP'),\n",
       " ('Билла', 'NNP'),\n",
       " ('Клинтона', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('AP', 'NNP'),\n",
       " ('отмечает', 'NNP'),\n",
       " (',', ','),\n",
       " ('что', 'NNP'),\n",
       " ('назначение', 'NNP'),\n",
       " ('Сперлинга', 'NNP'),\n",
       " ('стало', 'NNP'),\n",
       " ('частью', 'NNP'),\n",
       " ('перестановок', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('команде', 'NNP'),\n",
       " ('Обамы', 'NNP'),\n",
       " (',', ','),\n",
       " ('последовавших', 'NNP'),\n",
       " ('за', 'NNP'),\n",
       " ('прошедшими', 'NNP'),\n",
       " ('осенью', 'NNP'),\n",
       " ('2010', 'CD'),\n",
       " ('года', 'NNP'),\n",
       " ('промежуточными', 'NNP'),\n",
       " ('выборами', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('Конгресс', 'NNP'),\n",
       " (',', ','),\n",
       " ('в', 'NNP'),\n",
       " ('ходе', 'NNP'),\n",
       " ('которых', 'NNP'),\n",
       " ('Республиканской', 'NNP'),\n",
       " ('партии', 'NNP'),\n",
       " ('удалось', 'NNP'),\n",
       " ('существенно', 'NNP'),\n",
       " ('укрепить', 'NNP'),\n",
       " ('свои', 'NNP'),\n",
       " ('позиции', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Сообщается', 'NN'),\n",
       " ('также', 'NN'),\n",
       " (',', ','),\n",
       " ('что', 'NNP'),\n",
       " (',', ','),\n",
       " ('по', 'NNP'),\n",
       " ('мнению', 'NNP'),\n",
       " ('чиновников', 'NNP'),\n",
       " ('из', 'NNP'),\n",
       " ('президентской', 'NNP'),\n",
       " ('администрации', 'NNP'),\n",
       " (',', ','),\n",
       " ('Сперлинг', 'NNP'),\n",
       " ('произвел', 'NNP'),\n",
       " ('на', 'NNP'),\n",
       " ('Обаму', 'NNP'),\n",
       " ('большое', 'NNP'),\n",
       " ('впечатление', 'NNP'),\n",
       " (',', ','),\n",
       " ('когда', 'NNP'),\n",
       " ('помог', 'NNP'),\n",
       " ('ему', 'NNP'),\n",
       " ('достичь', 'NNP'),\n",
       " ('компромисса', 'NNP'),\n",
       " ('с', 'NNP'),\n",
       " ('республиканцами', 'NNP'),\n",
       " ('по', 'NNP'),\n",
       " ('вопросу', 'NNP'),\n",
       " ('о', 'NNP'),\n",
       " ('сохранении', 'NNP'),\n",
       " ('налоговых', 'NNP'),\n",
       " ('льгот', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Джин', 'VB'),\n",
       " ('Сперлинг', 'JJ'),\n",
       " ('сменит', 'NNP'),\n",
       " ('на', 'NNP'),\n",
       " ('посту', 'NNP'),\n",
       " ('главного', 'NNP'),\n",
       " ('экономического', 'NNP'),\n",
       " ('советника', 'NNP'),\n",
       " ('Ларри', 'NNP'),\n",
       " ('Саммерса', 'NNP'),\n",
       " ('(', '('),\n",
       " ('Larry', 'NNP'),\n",
       " ('Summers', 'NNP'),\n",
       " (')', ')'),\n",
       " (',', ','),\n",
       " ('который', 'JJ'),\n",
       " ('объявил', 'NNP'),\n",
       " ('о', 'NNP'),\n",
       " ('своем', 'NNP'),\n",
       " ('скором', 'NNP'),\n",
       " ('уходе', 'NNP'),\n",
       " ('еще', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('сентябре', 'NNP'),\n",
       " ('2010', 'CD'),\n",
       " ('года', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Днем', 'NN'),\n",
       " ('ранее', 'NN'),\n",
       " (',', ','),\n",
       " ('6', 'CD'),\n",
       " ('января', 'NN'),\n",
       " (',', ','),\n",
       " ('Барак', 'NNP'),\n",
       " ('Обама', 'NNP'),\n",
       " ('назначил', 'NNP'),\n",
       " ('нового', 'NNP'),\n",
       " ('главу', 'NNP'),\n",
       " ('своей', 'NNP'),\n",
       " ('администрации', 'NNP'),\n",
       " (';', ':'),\n",
       " ('им', 'NNP'),\n",
       " ('стал', 'NNP'),\n",
       " ('Уильям', 'NNP'),\n",
       " ('Дэйли', 'NNP'),\n",
       " ('(', '('),\n",
       " ('William', 'NNP'),\n",
       " ('Daley', 'NNP'),\n",
       " (')', ')'),\n",
       " ('.', '.'),\n",
       " ('Кроме', 'JJ'),\n",
       " ('того', 'NN'),\n",
       " (',', ','),\n",
       " ('в', 'NNP'),\n",
       " ('ближайшее', 'NNP'),\n",
       " ('время', 'NNP'),\n",
       " ('можно', 'NNP'),\n",
       " ('ожидать', 'NNP'),\n",
       " ('назначения', 'NNP'),\n",
       " ('нового', 'NNP'),\n",
       " ('пресс-секретаря', 'JJ'),\n",
       " ('президента', 'NNP'),\n",
       " (',', ','),\n",
       " ('поскольку', 'NNP'),\n",
       " ('Роберт', 'NNP'),\n",
       " ('Гиббс', 'NNP'),\n",
       " (',', ','),\n",
       " ('занимающий', 'NNP'),\n",
       " ('эту', 'NNP'),\n",
       " ('должность', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('настоящее', 'NNP'),\n",
       " ('время', 'NNP'),\n",
       " (',', ','),\n",
       " ('заявил', 'NNP'),\n",
       " ('о', 'NNP'),\n",
       " ('своей', 'NNP'),\n",
       " ('скорой', 'NNP'),\n",
       " ('отставке', 'NNP'),\n",
       " ('.', '.')]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {
    "id": "uRuODJpkIqlv"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "{(' '.join(c[0] for c in chunk), chunk.label() ) for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(text))) if hasattr(chunk, 'label') }"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{('AP', 'ORGANIZATION'),\n",
       " ('Associated Press', 'ORGANIZATION'),\n",
       " ('Gene', 'ORGANIZATION'),\n",
       " ('Larry Summers', 'PERSON'),\n",
       " ('William Daley', 'PERSON'),\n",
       " ('Барак Обама', 'PERSON'),\n",
       " ('Днем', 'PERSON'),\n",
       " ('Обама', 'PERSON'),\n",
       " ('Роберт Гиббс', 'PERSON'),\n",
       " ('Сперлинг', 'PERSON'),\n",
       " ('Уильям Дэйли', 'PERSON')}"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {
    "id": "XDdnL6EXJRt9"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "document.spans"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Ne5Span(\n",
       "     index='T1',\n",
       "     type='PER',\n",
       "     start=0,\n",
       "     stop=5,\n",
       "     text='Обама'\n",
       " ),\n",
       " Ne5Span(\n",
       "     index='T2',\n",
       "     type='PER',\n",
       "     start=68,\n",
       "     stop=79,\n",
       "     text='Барак Обама'\n",
       " ),\n",
       " Ne5Span(\n",
       "     index='T3',\n",
       "     type='ORG',\n",
       "     start=150,\n",
       "     stop=185,\n",
       "     text='Национального экономического совета'\n",
       " ),\n",
       " Ne5Span(\n",
       "     index='T4',\n",
       "     type='MEDIA',\n",
       "     start=225,\n",
       "     stop=241,\n",
       "     text='Associated Press'\n",
       " ),\n",
       " Ne5Span(\n",
       "     index='T5',\n",
       "     type='GEOPOLIT',\n",
       "     start=278,\n",
       "     stop=281,\n",
       "     text='США'\n",
       " ),\n",
       " Ne5Span(\n",
       "     index='T6',\n",
       "     type='PER',\n",
       "     start=282,\n",
       "     stop=311,\n",
       "     text='Джин Сперлинг (Gene Sperling)'\n",
       " ),\n",
       " Ne5Span(\n",
       "     index='T7',\n",
       "     type='PER',\n",
       "     start=370,\n",
       "     stop=375,\n",
       "     text='Обамы'\n",
       " ),\n",
       " Ne5Span(\n",
       "     index='T8',\n",
       "     type='PER',\n",
       "     start=546,\n",
       "     stop=554,\n",
       "     text='Сперлинг'\n",
       " ),\n",
       " Ne5Span(\n",
       "     index='T9',\n",
       "     type='ORG',\n",
       "     start=570,\n",
       "     stop=602,\n",
       "     text='Национальный экономический совет'\n",
       " ),\n",
       " Ne5Span(\n",
       "     index='T10',\n",
       "     type='PER',\n",
       "     start=642,\n",
       "     stop=656,\n",
       "     text='Билла Клинтона'\n",
       " ),\n",
       " Ne5Span(\n",
       "     index='T11',\n",
       "     type='MEDIA',\n",
       "     start=661,\n",
       "     stop=663,\n",
       "     text='AP'\n",
       " ),\n",
       " Ne5Span(\n",
       "     index='T12',\n",
       "     type='PER',\n",
       "     start=689,\n",
       "     stop=698,\n",
       "     text='Сперлинга'\n",
       " ),\n",
       " Ne5Span(\n",
       "     index='T13',\n",
       "     type='PER',\n",
       "     start=735,\n",
       "     stop=740,\n",
       "     text='Обамы'\n",
       " ),\n",
       " Ne5Span(\n",
       "     index='T14',\n",
       "     type='ORG',\n",
       "     start=813,\n",
       "     stop=821,\n",
       "     text='Конгресс'\n",
       " ),\n",
       " Ne5Span(\n",
       "     index='T15',\n",
       "     type='ORG',\n",
       "     start=838,\n",
       "     stop=860,\n",
       "     text='Республиканской партии'\n",
       " ),\n",
       " Ne5Span(\n",
       "     index='T16',\n",
       "     type='PER',\n",
       "     start=983,\n",
       "     stop=991,\n",
       "     text='Сперлинг'\n",
       " ),\n",
       " Ne5Span(\n",
       "     index='T17',\n",
       "     type='PER',\n",
       "     start=1004,\n",
       "     stop=1009,\n",
       "     text='Обаму'\n",
       " ),\n",
       " Ne5Span(\n",
       "     index='T18',\n",
       "     type='PER',\n",
       "     start=1129,\n",
       "     stop=1142,\n",
       "     text='Джин Сперлинг'\n",
       " ),\n",
       " Ne5Span(\n",
       "     index='T19',\n",
       "     type='PER',\n",
       "     start=1193,\n",
       "     stop=1223,\n",
       "     text='Ларри Саммерса (Larry Summers)'\n",
       " ),\n",
       " Ne5Span(\n",
       "     index='T20',\n",
       "     type='PER',\n",
       "     start=1313,\n",
       "     stop=1324,\n",
       "     text='Барак Обама'\n",
       " ),\n",
       " Ne5Span(\n",
       "     index='T21',\n",
       "     type='PER',\n",
       "     start=1376,\n",
       "     stop=1404,\n",
       "     text='Уильям Дэйли (William Daley)'\n",
       " ),\n",
       " Ne5Span(\n",
       "     index='T22',\n",
       "     type='PER',\n",
       "     start=1506,\n",
       "     stop=1518,\n",
       "     text='Роберт Гиббс'\n",
       " )]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# displacy.render(text, jupyter=True, style='ent')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Spacy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# !pip install -U spacy\n",
    "# !python -m spacy info"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# !python -m spacy download ru_core_news_sm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "#!pip install -U spacy\n",
    "#!python -m spacy info\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import ru_core_news_md"
   ],
   "outputs": [],
   "metadata": {
    "id": "skYaNCiC5xM4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import spacy\n",
    "from spacy.lang.ru.examples import sentences \n",
    "\n",
    "nlp = spacy.load(\"ru_core_news_sm\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "from spacy.lang.ru import Russian"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# nlp = ru_core_news_md.load()\n",
    "nlp = spacy.load(\"ru_core_news_sm\")\n",
    "ny_bb = text #url_to_string('https://www.nytimes.com/2018/08/13/us/politics/peter-strzok-fired-fbi.html?hp&action=click&pgtype=Homepage&clickSource=story-heading&module=first-column-region&region=top-news&WT.nav=top-news')\n",
    "article = nlp(ny_bb)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "displacy.render(article, jupyter=True, style='ent')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Обама\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " назначил своего нового советника по экономическим вопросам \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Барак Обама\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " в пятницу, 7 января, официально объявил о назначении нового директора \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Национального экономического совета администрации президента\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". Как передает \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Associated Press\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", им стал советник министра финансов \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    США\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Джин Сперлинг (Gene Sperling)\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ". По новой должности чиновник станет главным советником \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Обамы\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " по экономическим вопросам и ключевой фигурой в формировании экономической политики американского президента, влияя, в частности, на формирование федерального бюджета. Сперлинг уже возглавлял \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Национальный экономический совет\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " в в 1996-2000 годах, при администрации \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Билла Клинтона\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ". \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    AP\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " отмечает, что назначение \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Сперлинга\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " стало частью перестановок в команде \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Обамы\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", последовавших за прошедшими осенью 2010 года промежуточными выборами в \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Конгресс\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", в ходе которых \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Республиканской партии\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " удалось существенно укрепить свои позиции. Сообщается также, что, по мнению чиновников из президентской администрации, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Сперлинг\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " произвел на \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Обаму\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " большое впечатление, когда помог ему достичь компромисса с республиканцами по вопросу о сохранении налоговых льгот. \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Джин Сперлинг\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " сменит на посту главного экономического советника \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ларри Саммерса (Larry Summers)\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", который объявил о своем скором уходе еще в сентябре 2010 года. Днем ранее, 6 января, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Барак Обама\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " назначил нового главу своей администрации; им стал \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Уильям Дэйли (William Daley)\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ". Кроме того, в ближайшее время можно ожидать назначения нового пресс-секретаря президента, поскольку \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Роберт Гиббс\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", занимающий эту должность в настоящее время, заявил о своей скорой отставке. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# установка deeppavlov\n",
    "\n",
    "# !pip uninstall -y tensorflow tensorflow-gpu\n",
    "# !pip install numpy scipy librosa unidecode inflect librosa transformers\n",
    "# !pip install deeppavlov"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2kd-emBao1u-",
    "outputId": "a31344d7-177b-4b5f-b49e-4d4201f529ff"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://files.deeppavlov.ai/0.16/ner/ner_rus_bert_torch.tar.gz"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# !python -m deeppavlov install squad_bert\n",
    "# !python -m deeppavlov install ner_ontonotes"
   ],
   "outputs": [],
   "metadata": {
    "id": "KY96lqBzsZJ_"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# !activate deeppavlov_env\n",
    "# !python -m spacy download en\n",
    "# !python -m spacy download en_core_web_sm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# !pip install razdel\n",
    "# !pip install numpy==1.19.5\n",
    "# !pip install fasttext"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import deeppavlov\n",
    "from deeppavlov import configs, build_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "deeppavlov_ner = build_model(configs.ner.ner_bert_ent_and_type_rus, download=False)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wsegbgCbrzy_",
    "outputId": "98fbfd4e-0fff-433a-9c24-2fa56ab7d241"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from razdel import tokenize\n",
    "from sklearn.metrics import confusion_matrix, classification_report,f1_score, accuracy_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "rus_document = text #\"Нью-Йорк, США, 30 апреля 2020, 01:01 — REGNUM В администрации президента США Дональда Трампа планируют пройти все этапы создания вакцины от коронавируса в ускоренном темпе и выпустить 100 млн доз до конца 2020 года, передаёт агентство Bloomberg со ссылкой на осведомлённые источники\"\n",
    "deeppavlov_ner([rus_document])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[['Обама',\n",
       "   'назначил',\n",
       "   'своего',\n",
       "   'нового',\n",
       "   'советника',\n",
       "   'по',\n",
       "   'экономическим',\n",
       "   'вопросам',\n",
       "   'Барак',\n",
       "   'Обама',\n",
       "   'в',\n",
       "   'пятницу',\n",
       "   ',',\n",
       "   '7',\n",
       "   'января',\n",
       "   ',',\n",
       "   'официально',\n",
       "   'объявил',\n",
       "   'о',\n",
       "   'назначении',\n",
       "   'нового',\n",
       "   'директора',\n",
       "   'Национального',\n",
       "   'экономического',\n",
       "   'совета',\n",
       "   'администрации',\n",
       "   'президента',\n",
       "   '.',\n",
       "   'Как',\n",
       "   'передает',\n",
       "   'Associated',\n",
       "   'Press',\n",
       "   ',',\n",
       "   'им',\n",
       "   'стал',\n",
       "   'советник',\n",
       "   'министра',\n",
       "   'финансов',\n",
       "   'США',\n",
       "   'Джин',\n",
       "   'Сперлинг',\n",
       "   '(',\n",
       "   'Gene',\n",
       "   'Sperling',\n",
       "   ')',\n",
       "   '.',\n",
       "   'По',\n",
       "   'новой',\n",
       "   'должности',\n",
       "   'чиновник',\n",
       "   'станет',\n",
       "   'главным',\n",
       "   'советником',\n",
       "   'Обамы',\n",
       "   'по',\n",
       "   'экономическим',\n",
       "   'вопросам',\n",
       "   'и',\n",
       "   'ключевой',\n",
       "   'фигурой',\n",
       "   'в',\n",
       "   'формировании',\n",
       "   'экономической',\n",
       "   'политики',\n",
       "   'американского',\n",
       "   'президента',\n",
       "   ',',\n",
       "   'влияя',\n",
       "   ',',\n",
       "   'в',\n",
       "   'частности',\n",
       "   ',',\n",
       "   'на',\n",
       "   'формирование',\n",
       "   'федерального',\n",
       "   'бюджета',\n",
       "   '.',\n",
       "   'Сперлинг',\n",
       "   'уже',\n",
       "   'возглавлял',\n",
       "   'Национальный',\n",
       "   'экономический',\n",
       "   'совет',\n",
       "   'в',\n",
       "   'в',\n",
       "   '1996',\n",
       "   '-',\n",
       "   '2000',\n",
       "   'годах',\n",
       "   ',',\n",
       "   'при',\n",
       "   'администрации',\n",
       "   'Билла',\n",
       "   'Клинтона',\n",
       "   '.',\n",
       "   'AP',\n",
       "   'отмечает',\n",
       "   ',',\n",
       "   'что',\n",
       "   'назначение',\n",
       "   'Сперлинга',\n",
       "   'стало',\n",
       "   'частью',\n",
       "   'перестановок',\n",
       "   'в',\n",
       "   'команде',\n",
       "   'Обамы',\n",
       "   ',',\n",
       "   'последовавших',\n",
       "   'за',\n",
       "   'прошедшими',\n",
       "   'осенью',\n",
       "   '2010',\n",
       "   'года',\n",
       "   'промежуточными',\n",
       "   'выборами',\n",
       "   'в',\n",
       "   'Конгресс',\n",
       "   ',',\n",
       "   'в',\n",
       "   'ходе',\n",
       "   'которых',\n",
       "   'Республиканской',\n",
       "   'партии',\n",
       "   'удалось',\n",
       "   'существенно',\n",
       "   'укрепить',\n",
       "   'свои',\n",
       "   'позиции',\n",
       "   '.',\n",
       "   'Сообщается',\n",
       "   'также',\n",
       "   ',',\n",
       "   'что',\n",
       "   ',',\n",
       "   'по',\n",
       "   'мнению',\n",
       "   'чиновников',\n",
       "   'из',\n",
       "   'президентской',\n",
       "   'администрации',\n",
       "   ',',\n",
       "   'Сперлинг',\n",
       "   'произвел',\n",
       "   'на',\n",
       "   'Обаму',\n",
       "   'большое',\n",
       "   'впечатление',\n",
       "   ',',\n",
       "   'когда',\n",
       "   'помог',\n",
       "   'ему',\n",
       "   'достичь',\n",
       "   'компромисса',\n",
       "   'с',\n",
       "   'республиканцами',\n",
       "   'по',\n",
       "   'вопросу',\n",
       "   'о',\n",
       "   'сохранении',\n",
       "   'налоговых',\n",
       "   'льгот',\n",
       "   '.',\n",
       "   'Джин',\n",
       "   'Сперлинг',\n",
       "   'сменит',\n",
       "   'на',\n",
       "   'посту',\n",
       "   'главного',\n",
       "   'экономического',\n",
       "   'советника',\n",
       "   'Ларри',\n",
       "   'Саммерса',\n",
       "   '(',\n",
       "   'Larry',\n",
       "   'Summers',\n",
       "   ')',\n",
       "   ',',\n",
       "   'который',\n",
       "   'объявил',\n",
       "   'о',\n",
       "   'своем',\n",
       "   'скором',\n",
       "   'уходе',\n",
       "   'еще',\n",
       "   'в',\n",
       "   'сентябре',\n",
       "   '2010',\n",
       "   'года',\n",
       "   '.',\n",
       "   'Днем',\n",
       "   'ранее',\n",
       "   ',',\n",
       "   '6',\n",
       "   'января',\n",
       "   ',',\n",
       "   'Барак',\n",
       "   'Обама',\n",
       "   'назначил',\n",
       "   'нового',\n",
       "   'главу',\n",
       "   'своей',\n",
       "   'администрации',\n",
       "   ';',\n",
       "   'им',\n",
       "   'стал',\n",
       "   'Уильям',\n",
       "   'Дэйли',\n",
       "   '(',\n",
       "   'William',\n",
       "   'Daley',\n",
       "   ')',\n",
       "   '.',\n",
       "   'Кроме',\n",
       "   'того',\n",
       "   ',',\n",
       "   'в',\n",
       "   'ближайшее',\n",
       "   'время',\n",
       "   'можно',\n",
       "   'ожидать',\n",
       "   'назначения',\n",
       "   'нового',\n",
       "   'пресс',\n",
       "   '-',\n",
       "   'секретаря',\n",
       "   'президента',\n",
       "   ',',\n",
       "   'поскольку',\n",
       "   'Роберт',\n",
       "   'Гиббс',\n",
       "   ',',\n",
       "   'занимающий',\n",
       "   'эту',\n",
       "   'должность',\n",
       "   'в',\n",
       "   'настоящее',\n",
       "   'время',\n",
       "   ',',\n",
       "   'заявил',\n",
       "   'о',\n",
       "   'своей',\n",
       "   'скорой',\n",
       "   'отставке',\n",
       "   '.']],\n",
       " array([[[8.14647913e-01, 1.80241644e-01, 5.11043612e-03],\n",
       "         [9.98945057e-01, 9.52236878e-04, 1.02792299e-04],\n",
       "         [9.98923600e-01, 9.45674255e-04, 1.30693603e-04],\n",
       "         [9.98187602e-01, 1.51930377e-03, 2.93028483e-04],\n",
       "         [9.96474087e-01, 2.92812660e-03, 5.97789185e-04],\n",
       "         [9.95471239e-01, 3.98468226e-03, 5.44059323e-04],\n",
       "         [9.84513223e-01, 1.29227927e-02, 2.56405887e-03],\n",
       "         [9.93230939e-01, 5.79957291e-03, 9.69420304e-04],\n",
       "         [3.76012504e-01, 6.21380627e-01, 2.60689855e-03],\n",
       "         [6.29827380e-02, 9.36100900e-01, 9.16392135e-04],\n",
       "         [9.98907328e-01, 9.44329135e-04, 1.48388877e-04],\n",
       "         [9.98239636e-01, 1.52256247e-03, 2.37807049e-04],\n",
       "         [9.98029053e-01, 1.66911422e-03, 3.01789056e-04],\n",
       "         [9.95272815e-01, 4.23194468e-03, 4.95176064e-04],\n",
       "         [9.89673376e-01, 9.34812147e-03, 9.78514552e-04],\n",
       "         [9.96227503e-01, 3.24106845e-03, 5.31393976e-04],\n",
       "         [9.98380899e-01, 1.38454966e-03, 2.34569947e-04],\n",
       "         [9.98305082e-01, 1.51722226e-03, 1.77703885e-04],\n",
       "         [9.99473512e-01, 4.71359759e-04, 5.51894263e-05],\n",
       "         [9.98805285e-01, 1.07681635e-03, 1.17877164e-04],\n",
       "         [9.97821569e-01, 1.91732962e-03, 2.61125853e-04],\n",
       "         [9.94141877e-01, 5.33530535e-03, 5.22718357e-04],\n",
       "         [8.45198691e-01, 1.49126485e-01, 5.67487115e-03],\n",
       "         [7.00041890e-01, 2.88165390e-01, 1.17927762e-02],\n",
       "         [6.91069424e-01, 3.01315188e-01, 7.61537999e-03],\n",
       "         [8.03545713e-01, 1.89567581e-01, 6.88671134e-03],\n",
       "         [9.01696622e-01, 9.30851102e-02, 5.21820132e-03],\n",
       "         [9.97985601e-01, 1.81133253e-03, 2.03087358e-04],\n",
       "         [9.99304771e-01, 6.20324165e-04, 7.49464598e-05],\n",
       "         [9.98833120e-01, 1.05147948e-03, 1.15346382e-04],\n",
       "         [9.01429176e-01, 9.45978835e-02, 3.97298671e-03],\n",
       "         [8.77946973e-01, 1.17714599e-01, 4.33830265e-03],\n",
       "         [9.98605192e-01, 1.27054984e-03, 1.24243568e-04],\n",
       "         [9.99406576e-01, 5.15649386e-04, 7.77719688e-05],\n",
       "         [9.99241590e-01, 6.62941486e-04, 9.55532814e-05],\n",
       "         [9.95418906e-01, 4.18925146e-03, 3.91776441e-04],\n",
       "         [9.76012528e-01, 2.26606969e-02, 1.32672000e-03],\n",
       "         [9.12058830e-01, 8.28440264e-02, 5.09717828e-03],\n",
       "         [9.45046961e-01, 5.12996539e-02, 3.65338963e-03],\n",
       "         [9.28348064e-01, 7.05900267e-02, 1.06189004e-03],\n",
       "         [7.86535740e-01, 2.11403638e-01, 2.06065178e-03],\n",
       "         [9.81214881e-01, 1.80900712e-02, 6.94986666e-04],\n",
       "         [8.39139581e-01, 1.57890782e-01, 2.96969851e-03],\n",
       "         [6.82021260e-01, 3.15391004e-01, 2.58773006e-03],\n",
       "         [9.90206182e-01, 9.32596624e-03, 4.67831473e-04],\n",
       "         [9.97423291e-01, 2.35531107e-03, 2.21417184e-04],\n",
       "         [9.98739660e-01, 1.07250887e-03, 1.87877406e-04],\n",
       "         [9.97228682e-01, 2.38521188e-03, 3.86065047e-04],\n",
       "         [9.96686876e-01, 2.70650326e-03, 6.06620626e-04],\n",
       "         [9.96162415e-01, 3.13904812e-03, 6.98475924e-04],\n",
       "         [9.98762727e-01, 1.07239455e-03, 1.64904792e-04],\n",
       "         [9.97635126e-01, 2.11235206e-03, 2.52458587e-04],\n",
       "         [9.95077431e-01, 4.41779196e-03, 5.04832366e-04],\n",
       "         [9.14741337e-01, 8.20879340e-02, 3.17068910e-03],\n",
       "         [9.52050328e-01, 4.55652922e-02, 2.38436158e-03],\n",
       "         [8.06407809e-01, 1.85797766e-01, 7.79439276e-03],\n",
       "         [8.24072421e-01, 1.67135313e-01, 8.79234727e-03],\n",
       "         [9.96534348e-01, 3.09110945e-03, 3.74576863e-04],\n",
       "         [9.97868657e-01, 1.89145142e-03, 2.39787725e-04],\n",
       "         [9.97485042e-01, 2.08550692e-03, 4.29386855e-04],\n",
       "         [9.96508777e-01, 3.11805704e-03, 3.73071380e-04],\n",
       "         [9.64141130e-01, 3.31628770e-02, 2.69605685e-03],\n",
       "         [7.35778689e-01, 2.52831936e-01, 1.13893673e-02],\n",
       "         [7.37670898e-01, 2.52855301e-01, 9.47382301e-03],\n",
       "         [6.63235009e-01, 3.27210546e-01, 9.55446437e-03],\n",
       "         [6.74730897e-01, 3.16137910e-01, 9.13118478e-03],\n",
       "         [9.93812084e-01, 5.44455275e-03, 7.43261480e-04],\n",
       "         [9.98466730e-01, 1.39948959e-03, 1.33743451e-04],\n",
       "         [9.98188913e-01, 1.58963341e-03, 2.21464623e-04],\n",
       "         [9.99221802e-01, 7.11098895e-04, 6.70036898e-05],\n",
       "         [9.96500373e-01, 3.18199443e-03, 3.17681697e-04],\n",
       "         [9.98103380e-01, 1.69560837e-03, 2.00934446e-04],\n",
       "         [9.97551501e-01, 2.19295407e-03, 2.55598512e-04],\n",
       "         [9.58758891e-01, 3.85014415e-02, 2.73972168e-03],\n",
       "         [6.54184103e-01, 3.35177124e-01, 1.06387781e-02],\n",
       "         [5.88433325e-01, 4.02297765e-01, 9.26890969e-03],\n",
       "         [9.93321240e-01, 6.34533167e-03, 3.33485048e-04],\n",
       "         [9.10206139e-01, 8.72709975e-02, 2.52287183e-03],\n",
       "         [9.98839438e-01, 1.02702132e-03, 1.33555368e-04],\n",
       "         [9.97927070e-01, 1.88345113e-03, 1.89486338e-04],\n",
       "         [6.08417034e-01, 3.82994443e-01, 8.58852826e-03],\n",
       "         [4.43919241e-01, 5.46179354e-01, 9.90135875e-03],\n",
       "         [5.65491915e-01, 4.25631016e-01, 8.87713768e-03],\n",
       "         [9.98883903e-01, 9.84590733e-04, 1.31519482e-04],\n",
       "         [9.98834193e-01, 1.04794174e-03, 1.17904412e-04],\n",
       "         [9.91624057e-01, 7.68320542e-03, 6.92701957e-04],\n",
       "         [9.96561110e-01, 3.18529899e-03, 2.53680890e-04],\n",
       "         [9.91176248e-01, 8.12710915e-03, 6.96597854e-04],\n",
       "         [9.98563707e-01, 1.29221205e-03, 1.44135833e-04],\n",
       "         [9.97965693e-01, 1.77373388e-03, 2.60693778e-04],\n",
       "         [9.97907043e-01, 1.84456434e-03, 2.48404249e-04],\n",
       "         [9.96324718e-01, 3.31685040e-03, 3.58470483e-04],\n",
       "         [9.54865038e-01, 4.39507626e-02, 1.18414988e-03],\n",
       "         [9.09137487e-01, 8.90451074e-02, 1.81739242e-03],\n",
       "         [9.95676458e-01, 4.23167460e-03, 9.19228623e-05],\n",
       "         [9.83905017e-01, 1.46858534e-02, 1.40911457e-03],\n",
       "         [9.97402847e-01, 2.41988734e-03, 1.77268521e-04],\n",
       "         [9.98426437e-01, 1.46499567e-03, 1.08491491e-04],\n",
       "         [9.98763561e-01, 1.15140644e-03, 8.49967546e-05],\n",
       "         [9.97866333e-01, 1.90860755e-03, 2.25025797e-04],\n",
       "         [9.62967455e-01, 3.56285311e-02, 1.40409952e-03],\n",
       "         [9.99153852e-01, 7.49591505e-04, 9.65913423e-05],\n",
       "         [9.99158382e-01, 7.56688009e-04, 8.49247590e-05],\n",
       "         [9.98418212e-01, 1.39577896e-03, 1.86043166e-04],\n",
       "         [9.98718023e-01, 1.14781107e-03, 1.34121772e-04],\n",
       "         [9.96925414e-01, 2.72419467e-03, 3.50330025e-04],\n",
       "         [9.55312967e-01, 4.28205840e-02, 1.86638208e-03],\n",
       "         [9.97739553e-01, 2.02759425e-03, 2.32903971e-04],\n",
       "         [9.98877227e-01, 1.02596858e-03, 9.67766391e-05],\n",
       "         [9.98738825e-01, 1.15002436e-03, 1.11180547e-04],\n",
       "         [9.97301161e-01, 2.45871954e-03, 2.40136127e-04],\n",
       "         [9.96692896e-01, 3.06335161e-03, 2.43641611e-04],\n",
       "         [9.86728728e-01, 1.21222902e-02, 1.14893424e-03],\n",
       "         [9.95824337e-01, 3.82980425e-03, 3.45974317e-04],\n",
       "         [9.92707193e-01, 6.75695529e-03, 5.35865780e-04],\n",
       "         [9.81505871e-01, 1.71611458e-02, 1.33289385e-03],\n",
       "         [9.78987157e-01, 1.95625387e-02, 1.45025505e-03],\n",
       "         [8.14054310e-01, 1.80381015e-01, 5.56477020e-03],\n",
       "         [9.95387137e-01, 4.11085365e-03, 5.02037525e-04],\n",
       "         [9.97796535e-01, 1.97534589e-03, 2.28122502e-04],\n",
       "         [9.95963216e-01, 3.54716275e-03, 4.89682599e-04],\n",
       "         [9.95632946e-01, 3.92834656e-03, 4.38631512e-04],\n",
       "         [6.24004364e-01, 3.67167890e-01, 8.82771891e-03],\n",
       "         [5.76274455e-01, 4.12651777e-01, 1.10737290e-02],\n",
       "         [9.91821587e-01, 7.18241557e-03, 9.96056246e-04],\n",
       "         [9.96063411e-01, 3.57801747e-03, 3.58555233e-04],\n",
       "         [9.95125473e-01, 4.40665009e-03, 4.67892300e-04],\n",
       "         [9.97319758e-01, 2.36011064e-03, 3.20146413e-04],\n",
       "         [9.94501352e-01, 4.69889631e-03, 7.99816742e-04],\n",
       "         [9.52829361e-01, 3.92413475e-02, 7.92918913e-03],\n",
       "         [9.98567820e-01, 1.33249070e-03, 9.96047238e-05],\n",
       "         [9.98972535e-01, 9.64274397e-04, 6.32731972e-05],\n",
       "         [9.99093652e-01, 8.48185387e-04, 5.81430431e-05],\n",
       "         [9.98766780e-01, 1.15101982e-03, 8.22752481e-05],\n",
       "         [9.98697996e-01, 1.18113135e-03, 1.20858822e-04],\n",
       "         [9.99104440e-01, 8.16236832e-04, 7.93555882e-05],\n",
       "         [9.97968733e-01, 1.88024004e-03, 1.51018365e-04],\n",
       "         [9.95293796e-01, 4.17102594e-03, 5.35062863e-04],\n",
       "         [9.94058490e-01, 5.56517346e-03, 3.76337674e-04],\n",
       "         [9.44726467e-01, 5.27040064e-02, 2.56955158e-03],\n",
       "         [9.46519971e-01, 5.08927628e-02, 2.58733286e-03],\n",
       "         [9.95818198e-01, 3.88066820e-03, 3.01194930e-04],\n",
       "         [8.68619740e-01, 1.28502667e-01, 2.87762540e-03],\n",
       "         [9.98318791e-01, 1.46746356e-03, 2.13763138e-04],\n",
       "         [9.97352123e-01, 2.35658651e-03, 2.91344331e-04],\n",
       "         [8.58984947e-01, 1.37711659e-01, 3.30340816e-03],\n",
       "         [9.97783005e-01, 1.93411799e-03, 2.82906491e-04],\n",
       "         [9.98430550e-01, 1.39156030e-03, 1.77799957e-04],\n",
       "         [9.97967303e-01, 1.76308991e-03, 2.69629527e-04],\n",
       "         [9.98419046e-01, 1.38842117e-03, 1.92537293e-04],\n",
       "         [9.98116493e-01, 1.62621879e-03, 2.57396372e-04],\n",
       "         [9.96740997e-01, 2.88009481e-03, 3.78876022e-04],\n",
       "         [9.97850299e-01, 1.94072013e-03, 2.08986210e-04],\n",
       "         [9.89825428e-01, 9.31828748e-03, 8.56255298e-04],\n",
       "         [9.95591521e-01, 4.04083030e-03, 3.67625034e-04],\n",
       "         [8.76719952e-01, 1.18537053e-01, 4.74297302e-03],\n",
       "         [9.21351492e-01, 7.66611993e-02, 1.98726938e-03],\n",
       "         [8.04956198e-01, 1.91172272e-01, 3.87149467e-03],\n",
       "         [7.92635024e-01, 2.03755796e-01, 3.60919675e-03],\n",
       "         [6.60260499e-01, 3.34507883e-01, 5.23165986e-03],\n",
       "         [6.92668617e-01, 3.00415814e-01, 6.91562332e-03],\n",
       "         [7.86313415e-01, 2.07014412e-01, 6.67214580e-03],\n",
       "         [9.96644855e-01, 3.13562737e-03, 2.19506532e-04],\n",
       "         [8.43061030e-01, 1.54715657e-01, 2.22342275e-03],\n",
       "         [6.00627601e-01, 3.96544874e-01, 2.82754889e-03],\n",
       "         [9.98922229e-01, 9.80585464e-04, 9.72284761e-05],\n",
       "         [9.99588430e-01, 3.77666700e-04, 3.39301041e-05],\n",
       "         [9.98635590e-01, 1.22056843e-03, 1.43762503e-04],\n",
       "         [9.98133361e-01, 1.62012561e-03, 2.46573356e-04],\n",
       "         [9.83761370e-01, 1.30447634e-02, 3.19377054e-03],\n",
       "         [9.94398534e-01, 4.91336873e-03, 6.88136846e-04],\n",
       "         [9.13865805e-01, 8.48286077e-02, 1.30555697e-03],\n",
       "         [7.72048712e-01, 2.25433692e-01, 2.51760660e-03],\n",
       "         [9.86014247e-01, 1.33570274e-02, 6.28769281e-04],\n",
       "         [7.77615249e-01, 2.19668865e-01, 2.71577621e-03],\n",
       "         [6.67293727e-01, 3.29281598e-01, 3.42466100e-03],\n",
       "         [9.91618872e-01, 7.91232754e-03, 4.68776008e-04],\n",
       "         [9.98451591e-01, 1.40245981e-03, 1.45946207e-04],\n",
       "         [9.98876631e-01, 1.01794442e-03, 1.05337705e-04],\n",
       "         [9.98605788e-01, 1.25935278e-03, 1.34833186e-04],\n",
       "         [9.98942673e-01, 9.61072743e-04, 9.61947953e-05],\n",
       "         [9.98813629e-01, 1.05994917e-03, 1.26487474e-04],\n",
       "         [9.98176336e-01, 1.59084494e-03, 2.32869541e-04],\n",
       "         [9.98333395e-01, 1.45130767e-03, 2.15237902e-04],\n",
       "         [9.99035001e-01, 8.58761894e-04, 1.06187901e-04],\n",
       "         [9.99169111e-01, 7.69549690e-04, 6.13759985e-05],\n",
       "         [9.93149459e-01, 6.25767559e-03, 5.92944096e-04],\n",
       "         [9.89039421e-01, 9.87014454e-03, 1.09049189e-03],\n",
       "         [9.97966170e-01, 1.83215993e-03, 2.01675633e-04],\n",
       "         [9.60287988e-01, 3.36243697e-02, 6.08764868e-03],\n",
       "         [9.98736560e-01, 1.11448928e-03, 1.48977429e-04],\n",
       "         [9.98113155e-01, 1.67805818e-03, 2.08758560e-04],\n",
       "         [9.98516858e-01, 1.30256172e-03, 1.80584160e-04],\n",
       "         [9.92993772e-01, 6.49926951e-03, 5.07053745e-04],\n",
       "         [9.85901177e-01, 1.29723717e-02, 1.12649403e-03],\n",
       "         [9.95731056e-01, 3.81998369e-03, 4.48960287e-04],\n",
       "         [2.25811213e-01, 7.71784961e-01, 2.40379549e-03],\n",
       "         [8.51420984e-02, 9.13442075e-01, 1.41579437e-03],\n",
       "         [9.98999536e-01, 8.96311540e-04, 1.04175931e-04],\n",
       "         [9.97726500e-01, 1.95463398e-03, 3.18884442e-04],\n",
       "         [9.97670710e-01, 1.96319842e-03, 3.66043590e-04],\n",
       "         [9.98500943e-01, 1.29401509e-03, 2.05030345e-04],\n",
       "         [9.95248973e-01, 3.90882418e-03, 8.42258858e-04],\n",
       "         [9.98627782e-01, 1.18386629e-03, 1.88291131e-04],\n",
       "         [9.99546111e-01, 3.93817463e-04, 6.00652857e-05],\n",
       "         [9.99093294e-01, 7.99507077e-04, 1.07189706e-04],\n",
       "         [8.82504880e-01, 1.15529671e-01, 1.96536351e-03],\n",
       "         [8.23621094e-01, 1.74306020e-01, 2.07296293e-03],\n",
       "         [9.70524490e-01, 2.85935178e-02, 8.81910848e-04],\n",
       "         [7.47773051e-01, 2.49116823e-01, 3.11017386e-03],\n",
       "         [6.47953749e-01, 3.48522961e-01, 3.52329295e-03],\n",
       "         [9.80397701e-01, 1.88826211e-02, 7.19749543e-04],\n",
       "         [9.97366011e-01, 2.42198771e-03, 2.11957420e-04],\n",
       "         [9.98261988e-01, 1.58480078e-03, 1.53300338e-04],\n",
       "         [9.98013377e-01, 1.83586194e-03, 1.50723237e-04],\n",
       "         [9.98320282e-01, 1.53519027e-03, 1.44449907e-04],\n",
       "         [9.98800993e-01, 1.08263362e-03, 1.16285788e-04],\n",
       "         [9.97800648e-01, 2.01947708e-03, 1.79806317e-04],\n",
       "         [9.97908950e-01, 1.90665782e-03, 1.84405682e-04],\n",
       "         [9.98015761e-01, 1.79575500e-03, 1.88501566e-04],\n",
       "         [9.98701215e-01, 1.20542827e-03, 9.32868279e-05],\n",
       "         [9.96572256e-01, 3.03715398e-03, 3.90594098e-04],\n",
       "         [9.93592203e-01, 5.76051185e-03, 6.47299981e-04],\n",
       "         [9.86774087e-01, 1.20435786e-02, 1.18235208e-03],\n",
       "         [9.80293393e-01, 1.85232926e-02, 1.18329597e-03],\n",
       "         [9.58822668e-01, 3.91657241e-02, 2.01152917e-03],\n",
       "         [9.42947268e-01, 5.34179434e-02, 3.63481161e-03],\n",
       "         [9.98752117e-01, 1.11805380e-03, 1.29791966e-04],\n",
       "         [9.97649848e-01, 2.13201670e-03, 2.18099667e-04],\n",
       "         [8.37780595e-01, 1.59674853e-01, 2.54465174e-03],\n",
       "         [7.67960727e-01, 2.28806391e-01, 3.23285279e-03],\n",
       "         [9.90807831e-01, 8.73577595e-03, 4.56427893e-04],\n",
       "         [9.98217165e-01, 1.65734731e-03, 1.25411214e-04],\n",
       "         [9.97943342e-01, 1.90033345e-03, 1.56316499e-04],\n",
       "         [9.95478809e-01, 3.95926321e-03, 5.61931054e-04],\n",
       "         [9.98589456e-01, 1.32988207e-03, 8.06086682e-05],\n",
       "         [9.94159579e-01, 5.44973230e-03, 3.90794332e-04],\n",
       "         [9.97017860e-01, 2.83099897e-03, 1.51218890e-04],\n",
       "         [9.97729003e-01, 2.07919278e-03, 1.91866435e-04],\n",
       "         [9.96661544e-01, 3.10352398e-03, 2.35021289e-04],\n",
       "         [9.96685445e-01, 3.11098900e-03, 2.03578747e-04],\n",
       "         [9.97659326e-01, 2.17858213e-03, 1.62155673e-04],\n",
       "         [9.94628608e-01, 4.92854603e-03, 4.42841934e-04],\n",
       "         [9.93217170e-01, 6.05311897e-03, 7.29721563e-04],\n",
       "         [9.97769594e-01, 2.04076478e-03, 1.89660001e-04]]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "deeppavlov_ner(['Example sentence'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[['Example', 'sentence']],\n",
       " array([[[0.92888683, 0.01832325, 0.05278989],\n",
       "         [0.39169678, 0.02965371, 0.5786495 ]]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "tokens, tags = deeppavlov_ner(['Саша живет в Нижнем Новгороде'])\n",
    "for tok, tag in zip(tokens[0], tags[0]):\n",
    "    print(f'{tok}\\t{tag}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Саша\t[0.05651835 0.94057846 0.00290323]\n",
      "живет\t[9.9798691e-01 1.7001238e-03 3.1296091e-04]\n",
      "в\t[9.9913329e-01 7.7816914e-04 8.8671215e-05]\n",
      "Нижнем\t[0.2384246  0.7537949  0.00778052]\n",
      "Новгороде\t[0.20955132 0.7804916  0.00995718]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Загрузим корпус слов. И вытащим из него все теги."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "dir = 'Collection5/'\n",
    "records = load_ne5(dir)\n",
    "\n",
    "words_docs = []\n",
    "for ix, rec in enumerate(records):\n",
    "    words = []\n",
    "    text = rec.text\n",
    "    for token in tokenize(text):\n",
    "        type_ent = 'OUT'\n",
    "        for ent in rec.spans:\n",
    "            if (token.start >= ent.start) and (token.stop <= ent.stop):\n",
    "                type_ent = ent.type\n",
    "                break\n",
    "        token.text = re.sub(\"[^a-zA-Z0-9а-яА-Я]\",\"\", token.text)\n",
    "        if (token.text == '') or (len(token.text) < 3):\n",
    "            continue\n",
    "        words.append([token.text, type_ent])\n",
    "    words_docs.extend(words)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "df_words = pd.DataFrame(words_docs, columns=['word', 'tag'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "df_words['tag'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OUT         142056\n",
       "PER          17266\n",
       "ORG          11525\n",
       "LOC           4503\n",
       "GEOPOLIT      3562\n",
       "MEDIA         2074\n",
       "Name: tag, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Проделаем аналогичную операцию на библиотеке deeppavlov."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from deeppavlov import configs, build_model\n",
    "\n",
    "ner = build_model(configs.ner.ner_rus, download=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "tokens, tags = ner(['Саша живет в Нижнем Новгороде'])\n",
    "for tok, tag in zip(tokens[0], tags[0]):\n",
    "    print(f'{tok}\\t{tag}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Саша\tB-PER\n",
      "живет\tO\n",
      "в\tO\n",
      "Нижнем\tB-LOC\n",
      "Новгороде\tI-LOC\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "dir = 'Collection5/'\n",
    "records = load_ne5(dir)\n",
    "\n",
    "words_docs = []\n",
    "for ix, rec in tqdm(enumerate(records)):\n",
    "    words = []\n",
    "    text = rec.text\n",
    "    tokens, tags = ner([text])\n",
    "    for token, tag in zip(tokens[0], tags[0]):\n",
    "        tag = re.sub(\"B-\",\"\",tag)\n",
    "        tag = re.sub(\"I-\",\"\",tag)\n",
    "        if tag == 'O':\n",
    "            tag = 'OUT'\n",
    "\n",
    "        token = re.sub(\"[^a-zA-Z0-9а-яА-Я]\",\"\", token)\n",
    "        if (token == '') or (len(token) < 3):\n",
    "            continue\n",
    "        \n",
    "        words.append([token, tag])     \n",
    "    words_docs.extend(words)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "1000it [01:28, 11.31it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "deeppavlov_words = pd.DataFrame(words_docs, columns=['word', 'tag'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "deeppavlov_words['tag'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OUT    141468\n",
       "PER     17216\n",
       "ORG     13307\n",
       "LOC      8908\n",
       "Name: tag, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "df_words['tag'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OUT         142056\n",
       "PER          17266\n",
       "ORG          11525\n",
       "LOC           4503\n",
       "GEOPOLIT      3562\n",
       "MEDIA         2074\n",
       "Name: tag, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "len(deeppavlov_words), len(df_words)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(180899, 180986)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Как видно наша предобученная сеть из DeepPavlov не распознает сущности GEOPOLIT и MEDIA.\n",
    "\n",
    "Судя по всему DeepPavlov выполняет какую-то дополнительную предобработку текста. \n",
    "т.к. к-во токенов после обработки в данной библиотеке уменьшилось относительно осходного значения.\n",
    " Из-за такого несоответствия в названиях токенов и том что к-во записей в результирующих таблицах отличаются вычесление к-ва предсказания становиться не тривиальной задачей."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "df_words_1 = df_words\n",
    "\n",
    "df_words_1['tag_pred']=''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "i = 0\n",
    "l = len(df_words_1)\n",
    "deep_len = len(deeppavlov_words)\n",
    "for j in tqdm(range(len(df_words_1))):\n",
    "    # print(df_words_1.iloc[j].word, deeppavlov_words.iloc[i].word)\n",
    "    # if df_words_1.iloc[j].word == deeppavlov_words.iloc[j].word:\n",
    "    if (re.findall(df_words_1.iloc[j].word,deeppavlov_words.iloc[i].word) !=[]) or (re.findall(deeppavlov_words.iloc[i].word, df_words_1.iloc[j].word) !=[]):\n",
    "        df_words_1['tag_pred'][j] = deeppavlov_words.iloc[i].tag\n",
    "        i+=1\n",
    "    else:\n",
    "        print(df_words_1.iloc[j].word, deeppavlov_words.iloc[j].word, df_words_1.iloc[j].tag)\n",
    "    \n",
    "    if i > deep_len:\n",
    "        break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "df_words_1.loc[(df_words_1['tag_pred']=='')]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>tag_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3111</th>\n",
       "      <td>press</td>\n",
       "      <td>MEDIA</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>выдвинули</td>\n",
       "      <td>OUT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>иные</td>\n",
       "      <td>OUT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3216</th>\n",
       "      <td>версии</td>\n",
       "      <td>OUT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3217</th>\n",
       "      <td>отставки</td>\n",
       "      <td>OUT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180981</th>\n",
       "      <td>проблемы</td>\n",
       "      <td>OUT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180982</th>\n",
       "      <td>оперативном</td>\n",
       "      <td>OUT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180983</th>\n",
       "      <td>порядке</td>\n",
       "      <td>OUT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180984</th>\n",
       "      <td>заявил</td>\n",
       "      <td>OUT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180985</th>\n",
       "      <td>Морозов</td>\n",
       "      <td>PER</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177529 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               word    tag tag_pred\n",
       "3111          press  MEDIA         \n",
       "3214      выдвинули    OUT         \n",
       "3215           иные    OUT         \n",
       "3216         версии    OUT         \n",
       "3217       отставки    OUT         \n",
       "...             ...    ...      ...\n",
       "180981     проблемы    OUT         \n",
       "180982  оперативном    OUT         \n",
       "180983      порядке    OUT         \n",
       "180984       заявил    OUT         \n",
       "180985      Морозов    PER         \n",
       "\n",
       "[177529 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вот и наши различия. С какого-то момента алгоритм сравнения затыкается и начинает пропускать всеподряд."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#================================================================================================#\n",
    "#================================================================================================#"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "__2.__  написать свой нер попробовать разные подходы\n",
    "    - передаём в сетку токен и его соседей\n",
    "    - передаём в сетку только токен"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ! Внимание\n",
    "   * Для запуска следующего кода потребутся Tensorflow версии **> 2.0**. Поэтому этот участок кода лучше всего запускать в виртуально окружении отличном от того в котором установлена библиотека **Deeppavlov**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Попробуем нейронную сеть."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# !wget http://www.labinform.ru/pub/named_entities/collection5.zip\n",
    "\n",
    "# !unzip collection5.zip\n",
    "# !pip install razdel"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report,f1_score, accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D, Conv1D, GRU, LSTM, Dropout, Input\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "from razdel import tokenize\n",
    "from corus import load_ne5"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def get_classification_report(y_test_true, y_test_pred):\n",
    "    print(classification_report(y_test_true, y_test_pred))\n",
    "\n",
    "    print('CONFUSION MATRIX\\n')\n",
    "    print(pd.crosstab(y_test_true, y_test_pred))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Загрузим размеченный корпус текстов."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "dir = 'Collection5/'\n",
    "records = load_ne5(dir)\n",
    "next(records)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Ne5Markup(\n",
       "    id='146',\n",
       "    text='Обама назначил своего нового советника по экономическим вопросам\\r\\n\\r\\nБарак Обама в пятницу, 7 января, официально объявил о назначении нового директора Национального экономического совета администрации президента. Как передает Associated Press, им стал советник министра финансов США Джин Сперлинг (Gene Sperling).\\r\\n\\r\\nПо новой должности чиновник станет главным советником Обамы по экономическим вопросам и ключевой фигурой в формировании экономической политики американского президента, влияя, в частности, на формирование федерального бюджета.\\r\\n\\r\\nСперлинг уже возглавлял Национальный экономический совет в в 1996-2000 годах, при администрации Билла Клинтона.\\r\\n\\r\\nAP отмечает, что назначение Сперлинга стало частью перестановок в команде Обамы, последовавших за прошедшими осенью 2010 года промежуточными выборами в Конгресс, в ходе которых Республиканской партии удалось существенно укрепить свои позиции.\\r\\n\\r\\nСообщается также, что, по мнению чиновников из президентской администрации, Сперлинг произвел на Обаму большое впечатление, когда помог ему достичь компромисса с республиканцами по вопросу о сохранении налоговых льгот.\\r\\n\\r\\nДжин Сперлинг сменит на посту главного экономического советника Ларри Саммерса (Larry Summers), который объявил о своем скором уходе еще в сентябре 2010 года.\\r\\n\\r\\nДнем ранее, 6 января, Барак Обама назначил нового главу своей администрации; им стал Уильям Дэйли (William Daley). Кроме того, в ближайшее время можно ожидать назначения нового пресс-секретаря президента, поскольку Роберт Гиббс, занимающий эту должность в настоящее время, заявил о своей скорой отставке. ',\n",
       "    spans=[Ne5Span(\n",
       "         index='T1',\n",
       "         type='PER',\n",
       "         start=0,\n",
       "         stop=5,\n",
       "         text='Обама'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T2',\n",
       "         type='PER',\n",
       "         start=68,\n",
       "         stop=79,\n",
       "         text='Барак Обама'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T3',\n",
       "         type='ORG',\n",
       "         start=150,\n",
       "         stop=185,\n",
       "         text='Национального экономического совета'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T4',\n",
       "         type='MEDIA',\n",
       "         start=225,\n",
       "         stop=241,\n",
       "         text='Associated Press'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T5',\n",
       "         type='GEOPOLIT',\n",
       "         start=278,\n",
       "         stop=281,\n",
       "         text='США'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T6',\n",
       "         type='PER',\n",
       "         start=282,\n",
       "         stop=311,\n",
       "         text='Джин Сперлинг (Gene Sperling)'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T7',\n",
       "         type='PER',\n",
       "         start=370,\n",
       "         stop=375,\n",
       "         text='Обамы'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T8',\n",
       "         type='PER',\n",
       "         start=546,\n",
       "         stop=554,\n",
       "         text='Сперлинг'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T9',\n",
       "         type='ORG',\n",
       "         start=570,\n",
       "         stop=602,\n",
       "         text='Национальный экономический совет'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T10',\n",
       "         type='PER',\n",
       "         start=642,\n",
       "         stop=656,\n",
       "         text='Билла Клинтона'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T11',\n",
       "         type='MEDIA',\n",
       "         start=661,\n",
       "         stop=663,\n",
       "         text='AP'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T12',\n",
       "         type='PER',\n",
       "         start=689,\n",
       "         stop=698,\n",
       "         text='Сперлинга'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T13',\n",
       "         type='PER',\n",
       "         start=735,\n",
       "         stop=740,\n",
       "         text='Обамы'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T14',\n",
       "         type='ORG',\n",
       "         start=813,\n",
       "         stop=821,\n",
       "         text='Конгресс'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T15',\n",
       "         type='ORG',\n",
       "         start=838,\n",
       "         stop=860,\n",
       "         text='Республиканской партии'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T16',\n",
       "         type='PER',\n",
       "         start=983,\n",
       "         stop=991,\n",
       "         text='Сперлинг'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T17',\n",
       "         type='PER',\n",
       "         start=1004,\n",
       "         stop=1009,\n",
       "         text='Обаму'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T18',\n",
       "         type='PER',\n",
       "         start=1129,\n",
       "         stop=1142,\n",
       "         text='Джин Сперлинг'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T19',\n",
       "         type='PER',\n",
       "         start=1193,\n",
       "         stop=1223,\n",
       "         text='Ларри Саммерса (Larry Summers)'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T20',\n",
       "         type='PER',\n",
       "         start=1313,\n",
       "         stop=1324,\n",
       "         text='Барак Обама'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T21',\n",
       "         type='PER',\n",
       "         start=1376,\n",
       "         stop=1404,\n",
       "         text='Уильям Дэйли (William Daley)'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T22',\n",
       "         type='PER',\n",
       "         start=1506,\n",
       "         stop=1518,\n",
       "         text='Роберт Гиббс'\n",
       "     )]\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "words_docs = []\n",
    "for ix, rec in enumerate(records):\n",
    "    words = []\n",
    "    for token in tokenize(rec.text):\n",
    "        type_ent = 'OUT'\n",
    "        for ent in rec.spans:\n",
    "            if (token.start >= ent.start) and (token.stop <= ent.stop):\n",
    "                type_ent = ent.type\n",
    "                break\n",
    "        words.append([token.text, type_ent])\n",
    "    words_docs.extend(words)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df_words = pd.DataFrame(words_docs, columns=['word', 'tag'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df_words['tag'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OUT         219021\n",
       "PER          21165\n",
       "ORG          13642\n",
       "LOC           4568\n",
       "GEOPOLIT      4355\n",
       "MEDIA         2479\n",
       "Name: tag, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "df_words.head(6)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Адвокат</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Мурадвердиева</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>опровергает</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>обвинения</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>в</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>контрабанде</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  tag\n",
       "0        Адвокат  OUT\n",
       "1  Мурадвердиева  PER\n",
       "2    опровергает  OUT\n",
       "3      обвинения  OUT\n",
       "4              в  OUT\n",
       "5    контрабанде  OUT"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df_words['word'], df_words['tag'])\n",
    "\n",
    "# labelEncode целевую переменную\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "encoder.classes_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['GEOPOLIT', 'LOC', 'MEDIA', 'ORG', 'OUT', 'PER'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "train_x.apply(len).max(axis=0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "valid_x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "231283    Министерство\n",
       "16162           китаец\n",
       "134288               )\n",
       "43696          которой\n",
       "149725             две\n",
       "              ...     \n",
       "222463       Гиоргадзе\n",
       "79942               !!\n",
       "249693       студентов\n",
       "82347         комитета\n",
       "50903         военными\n",
       "Name: word, Length: 66308, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "valid_data = tf.data.Dataset.from_tensor_slices((valid_x, valid_y))\n",
    "\n",
    "train_data = train_data.batch(16)\n",
    "valid_data = valid_data.batch(16)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_data = train_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "valid_data = valid_data.cache().prefetch(buffer_size=AUTOTUNE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def custom_standardization(input_data):\n",
    "    # Здесь может быть предобработка текста.\n",
    "    return input_data\n",
    "\n",
    "vocab_size = 30000\n",
    "seq_len = 10\n",
    "\n",
    "vectorize_layer = TextVectorization(  \n",
    "                            standardize=custom_standardization,\n",
    "                            max_tokens=vocab_size,\n",
    "                            output_mode='int',\n",
    "                            #ngrams=(1, 3),\n",
    "                            output_sequence_length=seq_len)\n",
    "\n",
    "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
    "text_data = train_data.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(text_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "len(vectorize_layer.get_vocabulary())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "29851"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "embedding_dim = 64\n",
    "\n",
    "class modelNER(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(modelNER, self).__init__()\n",
    "        self.emb = Embedding(vocab_size, embedding_dim)\n",
    "        self.gPool = GlobalMaxPooling1D()\n",
    "        self.fc1 = Dense(300, activation='relu')\n",
    "        self.fc2 = Dense(50, activation='relu')\n",
    "        self.fc3 = Dense(6, activation='softmax') # [OUT, PER, ORG, LOC, GEOPOLIT, MEDIA]\n",
    "\n",
    "    def call(self, x):\n",
    "        x = vectorize_layer(x)\n",
    "        x = self.emb(x)\n",
    "        pool_x = self.gPool(x)\n",
    "        \n",
    "        fc_x = self.fc1(pool_x)\n",
    "        fc_x = self.fc2(fc_x)\n",
    "        \n",
    "        concat_x = tf.concat([pool_x, fc_x], axis=1)\n",
    "        prob = self.fc3(concat_x)\n",
    "        return prob"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "mmodel = modelNER()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "mmodel.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "mmodel.fit( train_data,\n",
    "            validation_data=valid_data,\n",
    "            epochs=3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "12433/12433 [==============================] - 759s 60ms/step - loss: 0.2928 - accuracy: 0.9142 - val_loss: 0.2101 - val_accuracy: 0.9376\n",
      "Epoch 2/3\n",
      "12433/12433 [==============================] - 678s 55ms/step - loss: 0.1252 - accuracy: 0.9628 - val_loss: 0.3859 - val_accuracy: 0.8917\n",
      "Epoch 3/3\n",
      "12433/12433 [==============================] - 581s 47ms/step - loss: 0.1090 - accuracy: 0.9656 - val_loss: 0.3098 - val_accuracy: 0.8935\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f18f0403550>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "pred_y = mmodel.predict(valid_x)\n",
    "y_pred_classes = np.argmax(pred_y,axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "f1 = f1_score(valid_y, y_pred_classes, average= \"weighted\")\n",
    "f1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9008850878035005"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "print(f\"Classes: {encoder.classes_}\\r\\n\")\n",
    "\n",
    "get_classification_report(valid_y, y_pred_classes)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classes: ['GEOPOLIT' 'LOC' 'MEDIA' 'ORG' 'OUT' 'PER']\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      1093\n",
      "           1       0.86      0.77      0.81      1100\n",
      "           2       0.93      0.81      0.87       628\n",
      "           3       0.86      0.56      0.68      3428\n",
      "           4       0.97      0.92      0.94     54894\n",
      "           5       0.49      0.88      0.63      5165\n",
      "\n",
      "    accuracy                           0.89     66308\n",
      "   macro avg       0.84      0.81      0.81     66308\n",
      "weighted avg       0.92      0.89      0.90     66308\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0    0    1    2     3      4     5\n",
      "row_0                                  \n",
      "0      987   21    1    30     14    40\n",
      "1       14  843    2    24     34   183\n",
      "2        3    5  507    12     56    45\n",
      "3       68   46   23  1925   1007   359\n",
      "4        5   65   10   239  50422  4153\n",
      "5        1    0    1    12    586  4565\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Обучим нейронную сеть на биграммах и триграммах. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "def custom_standardization(input_data):\n",
    "    # Здесь может быть предобработка текста.\n",
    "    return input_data\n",
    "\n",
    "vocab_size = 30000\n",
    "seq_len = 10\n",
    "\n",
    "vectorize_layer = TextVectorization( \n",
    "                            standardize=custom_standardization,\n",
    "                            max_tokens=vocab_size,\n",
    "                            output_mode='int',\n",
    "                            ngrams=(1, 3),\n",
    "                            output_sequence_length=seq_len)\n",
    "\n",
    "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
    "text_data = train_data.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(text_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "mmodel = modelNER()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "mmodel.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "mmodel.fit( train_data,\n",
    "            validation_data=valid_data,\n",
    "            epochs=3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "12433/12433 [==============================] - 359s 29ms/step - loss: 0.2928 - accuracy: 0.9148 - val_loss: 0.2099 - val_accuracy: 0.9375\n",
      "Epoch 2/3\n",
      "12433/12433 [==============================] - 327s 26ms/step - loss: 0.1254 - accuracy: 0.9627 - val_loss: 0.4082 - val_accuracy: 0.8911\n",
      "Epoch 3/3\n",
      "12433/12433 [==============================] - 339s 27ms/step - loss: 0.1098 - accuracy: 0.9654 - val_loss: 0.2455 - val_accuracy: 0.8926\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f18f0309430>"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "pred_y = mmodel.predict(valid_x)\n",
    "y_pred_classes = np.argmax(pred_y,axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "f1 = f1_score(valid_y, y_pred_classes, average= \"weighted\")\n",
    "f1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.900048139443574"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "print(f\"Classes: {encoder.classes_}\\r\\n\")\n",
    "\n",
    "get_classification_report(valid_y, y_pred_classes)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classes: ['GEOPOLIT' 'LOC' 'MEDIA' 'ORG' 'OUT' 'PER']\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      1093\n",
      "           1       0.87      0.75      0.81      1100\n",
      "           2       0.92      0.81      0.86       628\n",
      "           3       0.83      0.57      0.67      3428\n",
      "           4       0.97      0.92      0.94     54894\n",
      "           5       0.49      0.88      0.63      5165\n",
      "\n",
      "    accuracy                           0.89     66308\n",
      "   macro avg       0.83      0.81      0.80     66308\n",
      "weighted avg       0.92      0.89      0.90     66308\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0    0    1    2     3      4     5\n",
      "row_0                                  \n",
      "0      987   20    1    31     14    40\n",
      "1       12  828    7    20     50   183\n",
      "2        3    5  507    12     56    45\n",
      "3       69   47   25  1940    988   359\n",
      "4        5   54   10   312  50361  4152\n",
      "5        1    0    1    12    586  4565\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# TODO #1 Организуем обучение нейронной сети на символьных N-граммах. Пока не до конца понятно как их подавать в слой!"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW5-colab.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "6b7c3ebca6b5b4a4b8af7b3624595a453b0710866dad47574474daaa4a66fc12"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('imageai_env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}