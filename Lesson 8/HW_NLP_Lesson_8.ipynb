{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Урок 8. Рекуррентные нейронные сети RNN LSTM GRU\n",
    "\n",
    "Материалы.<br>\n",
    "У вас лекционный ноутбук в архиве он с картинками и презентация тоже есть в архиве\n",
    "\n",
    "**Задание**\n",
    "\n",
    "На вебинаре мы говорили что долгое время CNN и RNN архитектуры были конурируещими.\n",
    "\n",
    "Постарайтесь выяснить какая архитектура больше подходит для задачи сантимент анализа на данных с вебинара\n",
    "  1. построить свёрточные архитектуры\n",
    "  2. построить различные архитектуры с RNN\n",
    "  3. построить совместные архитектуры CNN -> RNN и (RNN -> CNN)\n",
    "  4. сдлать выводы что получилось лучше\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!pip install stop_words"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: stop_words in /home/sergey/anaconda3/envs/imageai_env/lib/python3.8/site-packages (2018.7.23)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Попробуем запрограммировать простую рекурентную сеть. \n",
    "# Возьмем датасет с прошлого занятия\n",
    "\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import apostrophe_dict, emoticon_dict, short_word_dict  # см. файл utils.py\n",
    "\n",
    "tqdm.pandas()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "df_val = pd.read_csv(\"data/val.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df_train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id                                               text  class\n",
       "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
       "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
       "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
       "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
       "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "# Теперь повторим это для всех записей.\n",
    "def replase_words(text,dict_): \n",
    "    output = ''\n",
    "    for word in text.split(' '): # не будем делить текст на части будем искать подстроку в строке. это касается только смайликов.\n",
    "        word = word.strip()\n",
    "        if word in dict_.keys(): \n",
    "            output += ' ' + dict_[word]\n",
    "        else:\n",
    "            output += ' ' + word\n",
    "    return output\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = re.sub(\"[\\,]\",\"\",txt)\n",
    "    txt = re.sub(\"@[\\w]*\",\"\",txt)\n",
    "    # txt = re.sub(\"RT\",\"\",txt)\n",
    "    # Заменим эмодзи на соответствующие им слова.\n",
    "    txt = replase_words(txt, emoticon_dict)\n",
    "     # Заменим сокращения на их полные формы\n",
    "    txt = replase_words(txt, apostrophe_dict)\n",
    "    txt = replase_words(txt, short_word_dict)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)#[w for w in txt if len(w)>1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df_train['text'] = df_train['text'].progress_apply(preprocess_text)\n",
    "df_val['text'] = df_val['text'].progress_apply(preprocess_text)\n",
    "df_test['text'] = df_test['text'].progress_apply(preprocess_text)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 181467/181467 [02:49<00:00, 1072.07it/s]\n",
      "100%|██████████| 22683/22683 [00:23<00:00, 973.71it/s] \n",
      "100%|██████████| 22684/22684 [00:36<00:00, 626.89it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df_train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id                                               text  class\n",
       "0   0             уезжаааааааать ❤ тожена хотеть уезжать      0\n",
       "1   1  rt ребята девчата кино любовь завтра вотэтолюбовь      1\n",
       "2   2                  rt ктоненавидеть пробка ретвит rt      0\n",
       "3   3  rt хотеться котлета покиевск запретный плод happy      1\n",
       "4   4                      босапоп есбосан бояться мороз      1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>уезжаааааааать ❤ тожена хотеть уезжать</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rt ребята девчата кино любовь завтра вотэтолюбовь</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt ктоненавидеть пробка ретвит rt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>rt хотеться котлета покиевск запретный плод happy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>босапоп есбосан бояться мороз</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "import numpy as np\n",
    "# import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D, SimpleRNN, LSTM, GRU, Masking,MaxPooling1D, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import TensorBoard \n",
    "# from tensorflow.keras.objectives import categorical_crossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "text_corpus_train = df_train['text'].values\n",
    "text_corpus_valid = df_val['text'].values\n",
    "text_corpus_test = df_test['text'].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "tokenizer = Tokenizer(num_words=None, \n",
    "                     filters='#$%&()*+-<=>@[\\\\]^_`{|}~\\t\\n',\n",
    "                     lower = False, split = ' ')\n",
    "tokenizer.fit_on_texts(text_corpus_train)\n",
    "\n",
    "sequences_train = tokenizer.texts_to_sequences(text_corpus_train)\n",
    "sequences_val = tokenizer.texts_to_sequences(text_corpus_valid)\n",
    "sequences_test = tokenizer.texts_to_sequences(text_corpus_test)\n",
    "\n",
    "word_count = len(tokenizer.index_word) + 1\n",
    "training_length = max([len(i.split()) for i in text_corpus_train])\n",
    "\n",
    "X_train = pad_sequences(sequences_train, maxlen=training_length)\n",
    "X_valid = pad_sequences(sequences_val, maxlen=training_length)\n",
    "X_test = pad_sequences(sequences_test, maxlen=training_length)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "word_count, training_length"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(188690, 28)"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "y_train = df_train['class'].values\n",
    "y_val = df_val['class'].values\n",
    "# y_test = df_test['class'].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "results = {\n",
    "    \"NN\":[],\n",
    "    \"loss\":[],\n",
    "    \"accuracy\":[]\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    # validation_data=[X_test, y_test],\n",
    "                    # validation_batch_size=512,\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping]\n",
    "                    )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "319/319 [==============================] - 37s 116ms/step - loss: 0.4867 - accuracy: 0.7461 - val_loss: 0.4302 - val_accuracy: 0.7807\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=0)\n",
    "# print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "results['NN'].append(\"CNN\")\n",
    "results['loss'].append(score[0])\n",
    "results['accuracy'].append(score[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test score: 0.4386669099330902\n",
      "Test accuracy: 0.7766609191894531\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SimpleRNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(SimpleRNN(64))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    # validation_data=[X_test, y_test],\n",
    "                    # validation_batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping]\n",
    "                    )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "319/319 [==============================] - 26s 76ms/step - loss: 0.5003 - accuracy: 0.7322 - val_loss: 0.4365 - val_accuracy: 0.7813\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "results['NN'].append(\"SimpleRNN\")\n",
    "results['loss'].append(score[0])\n",
    "results['accuracy'].append(score[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test score: 0.4422447085380554\n",
      "Test accuracy: 0.7722523212432861\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LSTM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    # validation_data=[X_test, y_test],\n",
    "                    # validation_batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "319/319 [==============================] - 28s 68ms/step - loss: 0.4953 - accuracy: 0.7438 - val_loss: 0.4361 - val_accuracy: 0.7769\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "results['NN'].append(\"LSTM\")\n",
    "results['loss'].append(score[0])\n",
    "results['accuracy'].append(score[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test score: 0.4356742799282074\n",
      "Test accuracy: 0.775646984577179\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GRU"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(GRU(64))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "319/319 [==============================] - 26s 72ms/step - loss: 0.4920 - accuracy: 0.7441 - val_loss: 0.4393 - val_accuracy: 0.7714\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "results['NN'].append(\"GRU\")\n",
    "results['loss'].append(score[0])\n",
    "results['accuracy'].append(score[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test score: 0.4343072474002838\n",
      "Test accuracy: 0.7766168713569641\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=128,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv1D(64, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# model.add(Conv1D(128, 3))\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "319/319 [==============================] - 172s 537ms/step - loss: 0.4720 - accuracy: 0.7462 - val_loss: 0.4259 - val_accuracy: 0.7853\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "results['NN'].append(\"CNN\")\n",
    "results['loss'].append(score[0])\n",
    "results['accuracy'].append(score[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test score: 0.4320409595966339\n",
      "Test accuracy: 0.7788652181625366\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CNN+RNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=word_count,\n",
    "                    input_length=training_length,\n",
    "                    output_dim=30,\n",
    "                    trainable=True,\n",
    "                    mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(Conv1D(32, 2))\n",
    "model.add(Activation(\"relu\"))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(1))\n",
    "\n",
    "model.add(Conv1D(16, 2))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling1D(1))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(LSTM(32,return_sequences=True))\n",
    "model.add(LSTM(16))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# model.add(LSTM(64))\n",
    "\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Conv1D(128, 3))\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(32))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])\n",
    "                    \n",
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "results['NN'].append(\"CNN+RNN\")\n",
    "results['loss'].append(score[0])\n",
    "results['accuracy'].append(score[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "319/319 [==============================] - 41s 118ms/step - loss: 0.4979 - accuracy: 0.7290 - val_loss: 0.4315 - val_accuracy: 0.7803\n",
      "Test score: 0.43829575181007385\n",
      "Test accuracy: 0.7751179337501526\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=128,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv1D(64, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "# model.add(Conv1D(128, 3))\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])\n",
    "                    \n",
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "results['NN'].append(\"CNN+RNN\")\n",
    "results['loss'].append(score[0])\n",
    "results['accuracy'].append(score[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "319/319 [==============================] - 142s 437ms/step - loss: 0.4724 - accuracy: 0.7473 - val_loss: 0.4243 - val_accuracy: 0.7856\n",
      "Test score: 0.43146824836730957\n",
      "Test accuracy: 0.7774544954299927\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RNN+CNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "\n",
    "model.add(Masking(mask_value=0.0))\n",
    "model.add(GRU(128,return_sequences=True))\n",
    "# model.add(GlobalMaxPool1D())\n",
    "\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv1D(64, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# model.add(Masking(mask_value=0.0))\n",
    "# model.add(GRU(64))\n",
    "# model.add(Conv1D(128, 3))\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "# model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])\n",
    "                    \n",
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "results['NN'].append(\"RNN+CNN\")\n",
    "results['loss'].append(score[0])\n",
    "results['accuracy'].append(score[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "319/319 [==============================] - 143s 439ms/step - loss: 0.4754 - accuracy: 0.7459 - val_loss: 0.4343 - val_accuracy: 0.7808\n",
      "Test score: 0.44357970356941223\n",
      "Test accuracy: 0.7723405361175537\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=128,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "\n",
    "model.add(Masking(mask_value=0.0))\n",
    "model.add(LSTM(128,return_sequences=True))\n",
    "\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv1D(64, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# model.add(Masking(mask_value=0.0))\n",
    "# model.add(LSTM(64))\n",
    "# model.add(Conv1D(128, 3))\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])\n",
    "                    \n",
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "results['NN'].append(\"RNN+CNN\")\n",
    "results['loss'].append(score[0])\n",
    "results['accuracy'].append(score[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "319/319 [==============================] - 113s 340ms/step - loss: 0.4881 - accuracy: 0.7350 - val_loss: 0.4257 - val_accuracy: 0.7871\n",
      "Test score: 0.4330320358276367\n",
      "Test accuracy: 0.7791297435760498\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "pd.DataFrame(results)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           NN      loss  accuracy\n",
       "0         CNN  0.438667  0.776661\n",
       "1   SimpleRNN  0.442245  0.772252\n",
       "2        LSTM  0.435674  0.775647\n",
       "3         GRU  0.434307  0.776617\n",
       "4         CNN  0.432041  0.778865\n",
       "5     CNN+RNN  0.429332  0.782172\n",
       "6     CNN+RNN  0.431468  0.777454\n",
       "7     RNN+CNN  0.443580  0.772341\n",
       "8     RNN+CNN  0.433032  0.779130\n",
       "9     CNN+RNN  0.610862  0.712780\n",
       "10    CNN+RNN  0.637409  0.636997\n",
       "11    CNN+RNN  0.618773  0.643345\n",
       "12    CNN+RNN  0.439760  0.775691\n",
       "13    CNN+RNN  0.438773  0.776661\n",
       "14    CNN+RNN  0.435129  0.776352\n",
       "15    CNN+RNN  0.666276  0.544013\n",
       "16    CNN+RNN  0.436080  0.777675\n",
       "17    CNN+RNN  0.439279  0.775074\n",
       "18    CNN+RNN  0.434538  0.777234\n",
       "19    CNN+RNN  0.555629  0.701450\n",
       "20    CNN+RNN  0.435648  0.779218\n",
       "21    CNN+RNN  0.444868  0.770797"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN</td>\n",
       "      <td>0.438667</td>\n",
       "      <td>0.776661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SimpleRNN</td>\n",
       "      <td>0.442245</td>\n",
       "      <td>0.772252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.435674</td>\n",
       "      <td>0.775647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.434307</td>\n",
       "      <td>0.776617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNN</td>\n",
       "      <td>0.432041</td>\n",
       "      <td>0.778865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CNN+RNN</td>\n",
       "      <td>0.429332</td>\n",
       "      <td>0.782172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CNN+RNN</td>\n",
       "      <td>0.431468</td>\n",
       "      <td>0.777454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RNN+CNN</td>\n",
       "      <td>0.443580</td>\n",
       "      <td>0.772341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RNN+CNN</td>\n",
       "      <td>0.433032</td>\n",
       "      <td>0.779130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CNN+RNN</td>\n",
       "      <td>0.610862</td>\n",
       "      <td>0.712780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CNN+RNN</td>\n",
       "      <td>0.637409</td>\n",
       "      <td>0.636997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CNN+RNN</td>\n",
       "      <td>0.618773</td>\n",
       "      <td>0.643345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CNN+RNN</td>\n",
       "      <td>0.439760</td>\n",
       "      <td>0.775691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CNN+RNN</td>\n",
       "      <td>0.438773</td>\n",
       "      <td>0.776661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CNN+RNN</td>\n",
       "      <td>0.435129</td>\n",
       "      <td>0.776352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CNN+RNN</td>\n",
       "      <td>0.666276</td>\n",
       "      <td>0.544013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CNN+RNN</td>\n",
       "      <td>0.436080</td>\n",
       "      <td>0.777675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CNN+RNN</td>\n",
       "      <td>0.439279</td>\n",
       "      <td>0.775074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CNN+RNN</td>\n",
       "      <td>0.434538</td>\n",
       "      <td>0.777234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CNN+RNN</td>\n",
       "      <td>0.555629</td>\n",
       "      <td>0.701450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CNN+RNN</td>\n",
       "      <td>0.435648</td>\n",
       "      <td>0.779218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CNN+RNN</td>\n",
       "      <td>0.444868</td>\n",
       "      <td>0.770797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('imageai_env': conda)"
  },
  "interpreter": {
   "hash": "6b7c3ebca6b5b4a4b8af7b3624595a453b0710866dad47574474daaa4a66fc12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}