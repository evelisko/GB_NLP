{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Урок 8. Рекуррентные нейронные сети RNN LSTM GRU\n",
    "\n",
    "Материалы.<br>\n",
    "У вас лекционный ноутбук в архиве он с картинками и презентация тоже есть в архиве\n",
    "\n",
    "**Задание**\n",
    "\n",
    "На вебинаре мы говорили что долгое время CNN и RNN архитектуры были конурируещими.\n",
    "\n",
    "Постарайтесь выяснить какая архитектура больше подходит для задачи сантимент анализа на данных с вебинара\n",
    "  1. построить свёрточные архитектуры\n",
    "  2. построить различные архитектуры с RNN\n",
    "  3. построить совместные архитектуры CNN -> RNN и (RNN -> CNN)\n",
    "  4. сдлать выводы что получилось лучше\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Решение. \n",
    "\n",
    "Загрузим датасет и выполним предобработку данных."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# !pip install stop_words"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import apostrophe_dict, emoticon_dict, short_word_dict  # см. файл utils.py\n",
    "\n",
    "tqdm.pandas()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/sergey/anaconda3/envs/deeppavlov_env/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_val = pd.read_csv(\"data/val.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df_train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  class\n",
       "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
       "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
       "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
       "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
       "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "# Теперь повторим это для всех записей.\n",
    "def replase_words(text,dict_): \n",
    "    output = ''\n",
    "    for word in text.split(' '): # TODO не будем делить текст на части будем искать подстроку в строке. это касается только смайликов.\n",
    "        word = word.strip()\n",
    "        if word in dict_.keys(): \n",
    "            output += ' ' + dict_[word]\n",
    "        else:\n",
    "            output += ' ' + word\n",
    "    return output\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = re.sub(\"[\\,]\",\"\",txt)\n",
    "    txt = re.sub(\"@[\\w]*\",\"\",txt)\n",
    "    # txt = re.sub(\"RT\",\"\",txt)\n",
    "    # Заменим эмодзи на соответствующие им слова.\n",
    "    txt = replase_words(txt, emoticon_dict)\n",
    "     # Заменим сокращения на их полные формы\n",
    "    txt = replase_words(txt, apostrophe_dict)\n",
    "    txt = replase_words(txt, short_word_dict)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)#[w for w in txt if len(w)>1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df_train['text'] = df_train['text'].progress_apply(preprocess_text)\n",
    "df_val['text'] = df_val['text'].progress_apply(preprocess_text)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 181467/181467 [05:38<00:00, 535.62it/s]\n",
      "100%|██████████| 22683/22683 [00:45<00:00, 493.93it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df_train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>уезжаааааааать ❤ тожена хотеть уезжать</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rt ребята девчата кино любовь завтра вотэтолюбовь</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt ктоненавидеть пробка ретвит rt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>rt хотеться котлета покиевск запретный плод happy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>босапоп есбосан бояться мороз</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  class\n",
       "0   0             уезжаааааааать ❤ тожена хотеть уезжать      0\n",
       "1   1  rt ребята девчата кино любовь завтра вотэтолюбовь      1\n",
       "2   2                  rt ктоненавидеть пробка ретвит rt      0\n",
       "3   3  rt хотеться котлета покиевск запретный плод happy      1\n",
       "4   4                      босапоп есбосан бояться мороз      1"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import numpy as np\n",
    "# import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D, SimpleRNN, LSTM, GRU, Masking,MaxPooling1D, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import TensorBoard \n",
    "# from tensorflow.keras.objectives import categorical_crossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "text_corpus_train = df_train['text'].values\n",
    "text_corpus_valid = df_val['text'].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "tokenizer = Tokenizer(num_words=None, \n",
    "                     filters='#$%&()*+-<=>@[\\\\]^_`{|}~\\t\\n',\n",
    "                     lower = False, split = ' ')\n",
    "tokenizer.fit_on_texts(text_corpus_train)\n",
    "\n",
    "sequences_train = tokenizer.texts_to_sequences(text_corpus_train)\n",
    "sequences_val = tokenizer.texts_to_sequences(text_corpus_valid)\n",
    "\n",
    "word_count = len(tokenizer.index_word) + 1\n",
    "training_length = max([len(i.split()) for i in text_corpus_train])\n",
    "\n",
    "X_train = pad_sequences(sequences_train, maxlen=training_length)\n",
    "X_valid = pad_sequences(sequences_val, maxlen=training_length)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "word_count, training_length"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(188809, 28)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "y_train = df_train['class'].values\n",
    "y_val = df_val['class'].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "results = {\n",
    "    \"NN\":[],\n",
    "    \"loss\":[],\n",
    "    \"accuracy\":[]\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping]\n",
    "                    )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 163320 samples, validate on 18147 samples\n",
      "Epoch 1/5\n",
      "163320/163320 [==============================] - 25s 153us/sample - loss: 0.5008 - acc: 0.7287 - val_loss: 0.4304 - val_acc: 0.7813\n",
      "Epoch 2/5\n",
      "163320/163320 [==============================] - 25s 151us/sample - loss: 0.3148 - acc: 0.8622 - val_loss: 0.4607 - val_acc: 0.7737\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=0)\n",
    "# print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "results['NN'].append(\"CNN\")\n",
    "results['loss'].append(score[0])\n",
    "results['accuracy'].append(score[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test score: 0.474356822238231\n",
      "Test accuracy: 0.7707975\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SimpleRNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(SimpleRNN(64))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping]\n",
    "                    )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 163320 samples, validate on 18147 samples\n",
      "Epoch 1/10\n",
      "163320/163320 [==============================] - 26s 158us/sample - loss: 0.4958 - acc: 0.7352 - val_loss: 0.4327 - val_acc: 0.7794\n",
      "Epoch 2/10\n",
      "163320/163320 [==============================] - 26s 157us/sample - loss: 0.2884 - acc: 0.8768 - val_loss: 0.4824 - val_acc: 0.7692\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "results['NN'].append(\"SimpleRNN\")\n",
    "results['loss'].append(score[0])\n",
    "results['accuracy'].append(score[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test score: 0.47969025303955587\n",
      "Test accuracy: 0.76850504\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LSTM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 163320 samples, validate on 18147 samples\n",
      "Epoch 1/10\n",
      "163320/163320 [==============================] - 40s 244us/sample - loss: 0.4944 - acc: 0.7456 - val_loss: 0.4351 - val_acc: 0.7787\n",
      "Epoch 2/10\n",
      "163320/163320 [==============================] - 39s 240us/sample - loss: 0.3167 - acc: 0.8640 - val_loss: 0.4694 - val_acc: 0.7711\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "results['NN'].append(\"LSTM\")\n",
    "results['loss'].append(score[0])\n",
    "results['accuracy'].append(score[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test score: 0.4719575312393754\n",
      "Test accuracy: 0.7721201\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GRU"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(GRU(64))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 163320 samples, validate on 18147 samples\n",
      "Epoch 1/10\n",
      "163320/163320 [==============================] - 36s 218us/sample - loss: 0.4905 - acc: 0.7459 - val_loss: 0.4366 - val_acc: 0.7768\n",
      "Epoch 2/10\n",
      "163320/163320 [==============================] - 36s 218us/sample - loss: 0.3113 - acc: 0.8650 - val_loss: 0.4670 - val_acc: 0.7698\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "results['NN'].append(\"GRU\")\n",
    "results['loss'].append(score[0])\n",
    "results['accuracy'].append(score[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test score: 0.46716090671411664\n",
      "Test accuracy: 0.7682405\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CNN+RNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=word_count,\n",
    "                    input_length=training_length,\n",
    "                    output_dim=30,\n",
    "                    trainable=True,\n",
    "                    mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(Conv1D(32, 2))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv1D(16, 2))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling1D(1))\n",
    "\n",
    "model.add(LSTM(16,return_sequences=True))\n",
    "\n",
    "model.add(LSTM(16))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])\n",
    "                    \n",
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "results['NN'].append(\"CNN+RNN\")\n",
    "results['loss'].append(score[0])\n",
    "results['accuracy'].append(score[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 163320 samples, validate on 18147 samples\n",
      "Epoch 1/10\n",
      "163320/163320 [==============================] - 31s 190us/sample - loss: 0.5119 - acc: 0.7212 - val_loss: 0.4338 - val_acc: 0.7818\n",
      "Epoch 2/10\n",
      "163320/163320 [==============================] - 30s 184us/sample - loss: 0.3099 - acc: 0.8636 - val_loss: 0.4615 - val_acc: 0.7719\n",
      "Test score: 0.46594160206470414\n",
      "Test accuracy: 0.77194375\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RNN+CNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "\n",
    "model.add(Masking(mask_value=0.0))\n",
    "model.add(LSTM(32,return_sequences=True))\n",
    "model.add(LSTM(32,return_sequences=True))\n",
    "\n",
    "model.add(Conv1D(32, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv1D(16, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])\n",
    "                    \n",
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "results['NN'].append(\"RNN+CNN\")\n",
    "results['loss'].append(score[0])\n",
    "results['accuracy'].append(score[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 163320 samples, validate on 18147 samples\n",
      "Epoch 1/10\n",
      "163320/163320 [==============================] - 111s 681us/sample - loss: 0.5264 - acc: 0.7075 - val_loss: 0.4364 - val_acc: 0.7807\n",
      "Epoch 2/10\n",
      "163320/163320 [==============================] - 105s 645us/sample - loss: 0.3252 - acc: 0.8563 - val_loss: 0.4596 - val_acc: 0.7741\n",
      "Test score: 0.46472977928681614\n",
      "Test accuracy: 0.7755147\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "pd.DataFrame(results)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN</td>\n",
       "      <td>0.474357</td>\n",
       "      <td>0.770797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SimpleRNN</td>\n",
       "      <td>0.479690</td>\n",
       "      <td>0.768505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.471958</td>\n",
       "      <td>0.772120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.467161</td>\n",
       "      <td>0.768241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNN+RNN</td>\n",
       "      <td>0.465942</td>\n",
       "      <td>0.771944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RNN+CNN</td>\n",
       "      <td>0.464730</td>\n",
       "      <td>0.775515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          NN      loss  accuracy\n",
       "0        CNN  0.474357  0.770797\n",
       "1  SimpleRNN  0.479690  0.768505\n",
       "2       LSTM  0.471958  0.772120\n",
       "3        GRU  0.467161  0.768241\n",
       "4    CNN+RNN  0.465942  0.771944\n",
       "5    RNN+CNN  0.464730  0.775515"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Резюме. \n",
    "\n",
    "Проверил различные варианты нейронных сетей. Экспериментрировал с числом слоев CNN и RNN. Качество от этого не сильно изменялось. По итогу, все рассмотренные архитектуры показали примерно оденаковый результат.  "
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('deeppavlov_env': conda)"
  },
  "interpreter": {
   "hash": "5331902c2ae29ddc0e99dbf5873f636b999b11fa6a0c261c517ecf54ceaf1dcc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}