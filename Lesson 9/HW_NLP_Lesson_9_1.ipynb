{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Решение"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " * Добавить отслежевание точности. \n",
    " * Увеличить к-во эпох обучения. хотябы до 200."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "import warnings # Не показывать предупреждения.\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "path_to_file = 'evgenyi_onegin.txt'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "# length of text is the number of characters in it\n",
    "print('Length of text: {} characters'.format(len(text)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Length of text: 286984 characters\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "print(text[:500])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Александр Сергеевич Пушкин\n",
      "\n",
      "                                Евгений Онегин\n",
      "                                Роман в стихах\n",
      "\n",
      "                        Не мысля гордый свет забавить,\n",
      "                        Вниманье дружбы возлюбя,\n",
      "                        Хотел бы я тебе представить\n",
      "                        Залог достойнее тебя,\n",
      "                        Достойнее души прекрасной,\n",
      "                        Святой исполненной мечты,\n",
      "                        Поэзии живой и ясной,\n",
      "                        Высо\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "text = text + text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "# The unique characters in the file\n",
    "#  Отсортируем все символы в датасете и удалим повтряющиеся. \n",
    "vocab = sorted(set(text))\n",
    "print('{} unique characters'.format(len(vocab)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "131 unique characters\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "#  Сделаем перевод номеров симоволов в текст. \n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "text_as_int, text[:30], len(text_as_int), len(text)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([ 71, 110, 104, ..., 104, 121,   0]),\n",
       " 'Александр Сергеевич Пушкин\\n\\n  ',\n",
       " 573968,\n",
       " 573968)"
      ]
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### train and target"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "# The maximum length sentence you want for a single input in characters\n",
    "\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int) # ? Вот здесь не очень понятно. Зачем берут числа а не символы.\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(idx2char[i.numpy()])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "А\n",
      "л\n",
      "е\n",
      "к\n",
      "с\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "char_dataset.take(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<TakeDataset shapes: (), types: tf.int64>"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "# Выполним разбиение текста на последовательности длинной 100 символов.\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "# Выведем первые 5 батчей на экран.\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "'Александр Сергеевич Пушкин\\n\\n                                Евгений Онегин\\n                          '\n",
      "'      Роман в стихах\\n\\n                        Не мысля гордый свет забавить,\\n                        '\n",
      "'Вниманье дружбы возлюбя,\\n                        Хотел бы я тебе представить\\n                        '\n",
      "'Залог достойнее тебя,\\n                        Достойнее души прекрасной,\\n                        Свят'\n",
      "'ой исполненной мечты,\\n                        Поэзии живой и ясной,\\n                        Высоких д'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1] # Предсказываем по одному символу.\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "dataset\n",
    "\n",
    "# Разделим его на тренировочную и тестовую выборки."
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((100,), (100,)), types: (tf.int64, tf.int64)>"
      ]
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print the first example input and target values:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input data:  'Александр Сергеевич Пушкин\\n\\n                                Евгений Онегин\\n                         '\n",
      "Target data: 'лександр Сергеевич Пушкин\\n\\n                                Евгений Онегин\\n                          '\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 128\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "class RNNgenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units): #, batch_size):\n",
    "        super(RNNgenerator, self).__init__()\n",
    "        \n",
    "        self.emb = tf.keras.layers.Embedding(vocab_size, embedding_dim) #, batch_input_shape=[batch_size, None])\n",
    "                                 \n",
    "        self.gru1 = tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=False,\n",
    "                            recurrent_initializer='glorot_uniform')\n",
    "\n",
    "        self.gru2 = tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=False,\n",
    "                            recurrent_initializer='glorot_uniform')\n",
    "        self.gru3 = tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=False,\n",
    "                            recurrent_initializer='glorot_uniform')\n",
    "        \n",
    "        # self.lin_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, x):\n",
    "        emb_x = self.emb(x)\n",
    "        x = self.gru1(emb_x)\n",
    "        x = self.gru2(x)\n",
    "        x = self.gru3(x)\n",
    "\n",
    "        x = self.dense(x)\n",
    "        return x \n",
    "\n",
    "model = RNNgenerator(vocab_size,\n",
    "                     embedding_dim,\n",
    "                     rnn_units=rnn_units\n",
    "                     ) #,\n",
    "                    #  batch_size= BATCH_SIZE)\n",
    "                     \n",
    "# model.build(tf.TensorShape([1, None]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).emb.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).dense.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).gru1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).gru1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).gru1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).gru2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).gru2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).gru2.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).gru3.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).gru3.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).gru3.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).emb.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).dense.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).gru1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).gru1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).gru1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).gru2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).gru2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).gru2.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).gru3.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).gru3.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).gru3.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "# model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "# example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "# print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "# print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "model.compile(optimizer='adam', loss=loss, metrics='accuracy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Configure checkpoints"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './RNN_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                                filepath=checkpoint_prefix,\n",
    "                                save_freq=5,\n",
    "                                save_weights_only=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Execute the training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "EPOCHS = 3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "history = model.fit(dataset,\n",
    "                    epochs=EPOCHS,\n",
    "                    callbacks=[checkpoint_callback]\n",
    "                   )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "88/88 [==============================] - 87s 904ms/step - loss: 1.9452 - accuracy: 0.5616\n",
      "Epoch 2/3\n",
      "88/88 [==============================] - 81s 915ms/step - loss: 1.4290 - accuracy: 0.6062\n",
      "Epoch 3/3\n",
      "88/88 [==============================] - 80s 904ms/step - loss: 1.2909 - accuracy: 0.6317\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate text"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'./RNN_checkpoints/ckpt_3'"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Востановим модель из кеша."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "model = RNNgenerator(vocab_size, embedding_dim, rnn_units) #, batch_size=BATCH_SIZE)\n",
    "# )\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Генерация текста."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Number of characters to generate\n",
    "num_generate = 500\n",
    "\n",
    "# Low temperature results in more predictable text.\n",
    "# Higher temperature results in more surprising text.\n",
    "# Experiment to find the best setting.\n",
    "temperature = 1.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "def generate_text(model, start_string):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        \n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        # Pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "text_ = generate_text(model, start_string=u\"И вот идет уже \")\n",
    "print(text_)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "И вот идет уже ты\n",
      "  мачцяж8ю    а СдибAX2loх,        шg6oсРyщяМpVuьлrй  В       Нtьл,\n",
      "     ззхь:       В?\n",
      " дона          й, чвабзр}\n",
      " (Г37ай.\n",
      " Лfо\n",
      "     бж5БT}\n",
      "    ПФMомос):\n",
      "                спz7nьто\n",
      "  г     кой.\n",
      "   Озимдбcкидпю      Зыхрr\n",
      "   А\n",
      "             о\n",
      "          В            жяз    вли     ви\n",
      "     Всмк        во\n",
      "           Сей Т\n",
      "  Iiожы\n",
      " Бd; п :\n",
      " Унs{1Лu!нычпу   жИ   о  Вб1кувц}\n",
      "    А.   хдсмсжр8е;\n",
      "  ЛVkьс-   вы       Ду   V,\n",
      "   гй,\n",
      " Ре,        зт.\n",
      "         р39масбе\n",
      "  Дявой,\n",
      "         с\n",
      " Iiунемд;\n",
      "    Чь    \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Попробуем обучить модель с сохранением состояния."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "class RNNgenerator_1(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim) #, batch_input_shape=[batch_size, None])\n",
    "    self.gru1 = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.gru2 = tf.keras.layers.GRU(rnn_units,\n",
    "                                    return_sequences=True,\n",
    "                                    return_state=True,\n",
    "                                    recurrent_initializer='glorot_uniform')\n",
    "    self.gru3 = tf.keras.layers.GRU(rnn_units,\n",
    "                                    return_sequences=True,\n",
    "                                    return_state=True,\n",
    "                                    recurrent_initializer='glorot_uniform')\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, x, states=None, return_state=False):\n",
    "\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    if states is None:\n",
    "      states = self.gru1.get_initial_state(x)\n",
    "\n",
    "    x, states = self.gru1(x, initial_state=states)\n",
    "    x, states = self.gru2(x, initial_state=states)\n",
    "    x, states = self.gru3(x, initial_state=states)\n",
    "\n",
    "    x = self.dense(x)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './RNN_1_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                                filepath=checkpoint_prefix,\n",
    "                                save_freq=1,\n",
    "                                save_weights_only=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "source": [
    "model_1 = RNNgenerator_1(\n",
    "                 vocab_size= vocab_size,\n",
    "                 embedding_dim=embedding_dim,\n",
    "                \n",
    "                 rnn_units=rnn_units,\n",
    "                #  batch_size=BATCH_SIZE\n",
    "                )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model_1.build(tf.TensorShape([1, None]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "source": [
    "model_1.compile(optimizer='adam', loss=loss, metrics='accuracy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model_1.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "source": [
    "history = model_1.fit(dataset,\n",
    "                    epochs=EPOCHS,\n",
    "                    callbacks=[checkpoint_callback])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "88/88 [==============================] - 245s 3s/step - loss: 2.0053 - accuracy: 0.5598\n",
      "Epoch 2/3\n",
      "88/88 [==============================] - 265s 3s/step - loss: 1.4750 - accuracy: 0.5994\n",
      "Epoch 3/3\n",
      "88/88 [==============================] - 258s 3s/step - loss: 1.3158 - accuracy: 0.6243\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Генерация текста."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "source": [
    "num_generate = 500\n",
    "temperature = 1.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def generate_text(model, start_string, states):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions, states = model(input_eval, states=states, return_state=True)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        \n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        # Pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "\n",
    "  # @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_chars = [char2idx[s] for s in inputs]\n",
    "    input_ids = tf.expand_dims(input_chars, 0)\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(x=input_ids, states=states, return_state=True)\n",
    "    predicted_logits = tf.squeeze(predicted_logits, 0)\n",
    "    \n",
    "    # using a categorical distribution to predict the character returned by the model\n",
    "    predicted_logits = predicted_logits / temperature\n",
    "    predicted_id = tf.random.categorical(predicted_logits, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = idx2char[predicted_id]\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "source": [
    "states = None\n",
    "next_char = u\"И вот идет уже \"\n",
    "text_generated=[]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "source": [
    "for n in range(100):\n",
    "#   def generate_one_step(self, inputs, states=None):\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_chars = [char2idx[s] for s in next_char]\n",
    "    input_ids = tf.expand_dims(input_chars, 0)\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = model_1(x=input_ids, states=states, return_state=True)\n",
    "    predicted_logits = tf.squeeze(predicted_logits, 0)\n",
    "    \n",
    "    # using a categorical distribution to predict the character returned by the model\n",
    "    predicted_logits = predicted_logits / temperature\n",
    "    predicted_id = tf.random.categorical(predicted_logits, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = idx2char[predicted_id]\n",
    "\n",
    "    text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    # return predicted_chars, states"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "source": [
    "text = ''.join(text_generated)\n",
    "print(text)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "и-бобшлснвшт-ШвсмпдгббсдлрвялжсдурпНлтстртнсдвширтшбжддмвнлбувеавчмтчг.эжрнспетдлбмФунссп,тдкссщбувплв\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "source": [
    "# model_1.reset_states()\n",
    "one_step_model = OneStep(model_1, temperature)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "source": [
    "states = None\n",
    "next_char = u\"И вот идет уже \" # tf.constant([u\"И вот идет уже \"]) \n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "text = ''.join(result)\n",
    "print(text)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    <ipython-input-98-ccfd8629181e>:24 generate_one_step  *\n        predicted_id = tf.random.categorical(predicted_logits, num_samples=1)[-1, 0].numpy()\n    /home/sergey/anaconda3/envs/imageai_env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:401 __getattr__\n        self.__getattribute__(name)\n\n    AttributeError: 'Tensor' object has no attribute 'numpy'\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-61341a82c57a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mnext_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_step_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_one_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/imageai_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/imageai_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/envs/imageai_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m-> 3022\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/anaconda3/envs/imageai_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/imageai_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3279\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/imageai_env/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/imageai_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/imageai_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3969\u001b[0m     \u001b[0;31m# However, the replacer is still responsible for attaching self properly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3970\u001b[0m     \u001b[0;31m# TODO(mdan): Is it possible to do it here instead?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3971\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3972\u001b[0m   \u001b[0mweak_bound_method_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_method_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/imageai_env/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    <ipython-input-98-ccfd8629181e>:24 generate_one_step  *\n        predicted_id = tf.random.categorical(predicted_logits, num_samples=1)[-1, 0].numpy()\n    /home/sergey/anaconda3/envs/imageai_env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:401 __getattr__\n        self.__getattribute__(name)\n\n    AttributeError: 'Tensor' object has no attribute 'numpy'\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('imageai_env': conda)"
  },
  "interpreter": {
   "hash": "6b7c3ebca6b5b4a4b8af7b3624595a453b0710866dad47574474daaa4a66fc12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}